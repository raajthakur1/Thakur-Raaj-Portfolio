{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Raaj's Portfolio Welcome to my documentation for my engineering/CS courses. This site contains documentation for all of my assignments and projects. Purpose The goal of this portfolio is to: Document my assignments and projects for this course Provide resources and information to future AP Networking students Share my progress with the community Courses Engineering I Engineering II Civil Engineering Honors Data Analytics AP Networking Honors Senior Engineering Thank you for visiting my portfolio!","title":"Home"},{"location":"#raajs-portfolio","text":"Welcome to my documentation for my engineering/CS courses. This site contains documentation for all of my assignments and projects.","title":"Raaj's Portfolio"},{"location":"#purpose","text":"The goal of this portfolio is to: Document my assignments and projects for this course Provide resources and information to future AP Networking students Share my progress with the community","title":"Purpose"},{"location":"#courses","text":"Engineering I Engineering II Civil Engineering Honors Data Analytics AP Networking Honors Senior Engineering Thank you for visiting my portfolio!","title":"Courses"},{"location":"about/","text":"About Me My name is Raaj Thakur, and I'm in the Class of 2026 at Charlotte Latin School. Thank you for visiting my porfolio!","title":"About"},{"location":"about/#about-me","text":"My name is Raaj Thakur, and I'm in the Class of 2026 at Charlotte Latin School. Thank you for visiting my porfolio!","title":"About Me"},{"location":"courses/ap_networking/","text":"AP Networking Welcome to my documentation for the AP Networking course for the '25 - '26 school year. Projects Component Cards & Software Slips Command Line Interface Troubleshooting Determining Security Controls for Devices Implementing Security for Devices Networking and Data Movement Course Overview AP Networking is an AP Career Kickstart\u2122 course that teaches students how to configure network hardware, use protocols to enable reliable and accurate transmission of data, and to protect the transmission of data within and between computer networks. Technical skills learned include: Designing a secure network: Determining appropriate endpoints, network appliances, transmission media, and communication protocols to meet network requirements\u202f Enabling reliable, accurate, and secure transmission in the context of the OSI and TCP/IP models\u202f Configuring a secure network: Constructing, connecting, and documenting network components using appropriate media, communication protocols, and commands\u202f Troubleshooting common issues by testing connectivity, verifying configuration, and monitoring congestion\u202f Protecting computer networks: Identifying potential vulnerabilities in data, devices, and networks\u202f Implementing security controls that address potential vulnerabilities","title":"Overview"},{"location":"courses/ap_networking/#ap-networking","text":"Welcome to my documentation for the AP Networking course for the '25 - '26 school year.","title":"AP Networking"},{"location":"courses/ap_networking/#projects","text":"Component Cards & Software Slips Command Line Interface Troubleshooting Determining Security Controls for Devices Implementing Security for Devices Networking and Data Movement","title":"Projects"},{"location":"courses/ap_networking/#course-overview","text":"AP Networking is an AP Career Kickstart\u2122 course that teaches students how to configure network hardware, use protocols to enable reliable and accurate transmission of data, and to protect the transmission of data within and between computer networks.","title":"Course Overview"},{"location":"courses/ap_networking/#technical-skills-learned-include","text":"Designing a secure network: Determining appropriate endpoints, network appliances, transmission media, and communication protocols to meet network requirements\u202f Enabling reliable, accurate, and secure transmission in the context of the OSI and TCP/IP models\u202f Configuring a secure network: Constructing, connecting, and documenting network components using appropriate media, communication protocols, and commands\u202f Troubleshooting common issues by testing connectivity, verifying configuration, and monitoring congestion\u202f Protecting computer networks: Identifying potential vulnerabilities in data, devices, and networks\u202f Implementing security controls that address potential vulnerabilities","title":"Technical skills learned include:"},{"location":"courses/ap_networking/cli/","text":"Command Line Interface Project Introduction This project was focused on learning the command line interface of Linux and MacOS. Since Linux is the backbone of networks, IoT systems, and most servers, a strong understanding of the CLI is essential for working with networks. The project included various small activities to teach the class about the CLI, including: Map the Maze Part I: Conceptual overview of file system and introduction to CLI commands. Ubuntu CLI Tutorial: Practice with using CLI commands in an Ubuntu VM Map the Maze Part II: Technical exploration of using CLI commands in Ubuntu, MacOS, and how to share files between a host and VM House Activity: Practice using CLI commands to navigate a \"house\" through the terminal to execute tasks using cd , rm , ls , and more. Reflection Prerequisites In order to run Ubuntu on the M1 Mac minis in the computer lab, UTM was installed and Ubuntu was run inside a VM using Ubuntu with UTM, QEMU, and Apple Hypervisor for Apple Silicon. Also, MKDocs had to be installed on the Mac minis in order to build documentation and push it to GitHub. Unfortunately, simply running pip3 install mkdocs installed the mkdocs package installed it at ~/Library/Python/3.12, the user-specific folder that hosts packages tied to the system-wide python. However, by default, ZSH does not know about this folder, so the ZSH configuration profile had to be edited to point to this folder. Anytime mkdocs needed to be run, python3 -m mkdocs had to be specified rather than just being able to run mkdocs . To fix this issue, the process was: Type find ~/Library/Python -name mkdocs to find the specific path where mkdocs is installed. It should return /Users/*username*/Library/Python/3.xx/bin/mkdocs Open the ZSH configuration file with nano ~/.zshrc , then add this line: export PATH=\"$HOME/Library/Python/3.xx/bin:$PATH\" Refresh the ZSH profile with source ~/.zshrc Run mkdocs --version to confirm it works. It should return something like mkdocs, version 1.6.1 from /Users/*username*/Library/Python/3.xx/lib/python/site-packages/mkdocs (Python 3.xx) After completing these steps, MKDocs commands should be able to run by simply specifying mkdocs + command (build, serve, gh-deploy, etc.) rather than writing out python3 -m mkdocs . Although functionality remains unchanged, MKDocs is much easier and more convenient to work with after making these changes. Map the Maze Part I This assignment was an introduction to the file system of a computer. Important terms learned in this assignment include: Term Definition Root Directory Very top of the file system Folder/Directory Container used to organize files and other folders File Single digital object that holds data in various formats; contains a name and an extension Path \"Address\" of a file or folder inside the file system; either an absolute or relative path Absolute Path Complete address of a file or directory (starting from root) Relative Path Location of a file or directory starting from the working directory Drawing a Filesystem The first activity in this assignment was to draw out a file system with the root at the top, a home folder, 3 sub-folders, and 2 sample files. This section of the assignment was a simple introduction to the file system on a computer and helped in visualizing how a file system works. Text-Based Filesystem & Partner Activity The next activity was to type up a file system similar to the one that was drawn earlier then to trade file systems with a partner and ask them how they would find specific files in the file system. MacOS Terminal Commands After learning about the file system, we learned about essential MacOS/Linux commands and their purposes for the CLI, such as: Command Purpose pwd Prints working directory (absolute path) ls Lists files and directories within the current directory cd Changes working directory to specified directory mkdir Makes a new directory within the current working directory `touch`` Makes a new file in the current working directory or an cp Copies specified files to a specified directory mv Moves specified files to a specified directory open Opens any file or folder within the directory if just a file/folder name is given, or any file on the computer if an absolute path is specified rm Permanently removes specified files rmdir Permanently removes specified directories Ubuntu CLI Tutorial After learning about essential Linux & MacOS CLI commands, we practiced using them in an Ubuntu VM to get familiar with both the commands and using Ubuntu. Following this Ubuntu tutorial made by Canonical , I practiced using the command line in Ubuntu. I used commands like ls , cd , rm , touch , cp , and a couple more. Map the Maze Part II This activity was completed mostly within the Ubuntu VM and involved creating files and directories, editing them with nano , and transferring files between the host and VM. The instructions for the activity were: Run pwd to show current directory Outputs /home/ubuntu (username is ubuntu in the VM) Use cd Documents to enter the documents folder and run pwd to show path Outputs /home/ubuntu/Documents Make a folder titled MazeGame in Documents and enter it with mkdir MazeGame and cd MazeGame Create 3 clue files with touch clue1.txt clue2.txt clue3.txt Add \"Congratulations! You found the first clue.\" to clue1.txt with nano clue1.txt Screenshot of the nano text editor for clue1.txt in the Ubuntu VM. Share a file with the host by copying clue1.txt to ~/hostshare/ with cp clue1.txt ~/hostshare/ On the first attempt, clue1.txt did not show up on the Mac anywhere after putting in in the hostshare folder in the VM. In order to enable file sharing between the host and VM, I needed to follow the following steps: Make a folder anywhere on the Mac, then go into UTM settings and set that folder as the shared directory for the VM In the VM, type sudo mount -t davfs http://127.0.0.1:9843/ ~/hostshare/ in order to set ~/hostshare as a shared directory between the host (M1 Mac mini) and the VM Restart the VM, then mount the shared disk inside UTM by selecting a shared folder Once these steps were completed, files were able to be shared between the host and VM through ~/hostshare in the VM and the folder on the Mac that was selected as a shared directory in UTM's settings. House Sitting Activity The final activity in this project was the House Sitting Activity, where CLI commands were used to execute tasks within a \"house\" in the file system. Prerequisites Before starting, open terminal, change directories to Downloads with cd Downloads , then clone the project by typing sudo git clone https://github.com/thewangclass/CK-Building-Content-Knowledge-Workshop . Once this is completed, the house can be explored by following the instructions. Procedure Walk to the house and go inside. Use cd house Where can we go? ls returns bedroom1, bedroom2, garage, kitchen, and main_entrance Go inside the main entrance Use cd main_entrance See if there is anything around in the main entrance, such as instructions. ls returns instructions.txt, unopened_mail1.txt, unopened_mail2.txt, unopened_mail3.txt, and shoerack Open the instructions. Use cat instructions.txt to display the contents in the terminal. Leave the main entrance and go back to the house level. Use cd .. to go up one level in the file system in order to access other rooms Go inside the kitchen Use cd kitchen Check out what's inside the kitchen. ls returns apple, banana, cereal, crackers, donut, milk, orange \"Eat\" 2 items of food by removing them. Use rm -r apple donut to remove them. The -r argument after rm tells the rm command to act recursively and remove all of the arguments, not just the first one. You smell something, but you cannot see it. Find out what it is. Use ls -a in order to list all files, including hidden ones. This reveals everything from just writing ls , but also includes .rotten_bananas, a hidden file (files beginning with a period are hidden). Throw away the bananas. Use rm .rotten_bananas to delete the file Check the bedrooms to make sure everything is okay. Use cd .. to move up one level, then use cd bedroom1 to enter bedroom 1. Conduct a thorough search to look for anything unusual. Use ls -a to reveal everything, including hidden files. There's a hidden file titled .secret_diary.txt. Reveal the contents using cat .secret_diary.txt Now, enter bedroom 2 and explore it Use cd .. to move up one level then cd bedroom2 to enter the 2nd bedroom. Then, use ls -a to reveal all files. There was only regular items such as a chair, desk, and messy bed. Explore each item with ls -a [name] in order to list out the contents of each item. Desk should have a file titled search_desk.txt. The lights just went out and you are lost. Figure out where you currently are. Use pwd to print your location (directory) Navigate to the garage to figure out what is wrong with the lights. Use cd .. then cd garage to go to the garage. The lights suddenly come back. What is in the garage? Use ls -a to list the garage's contents. There are 3 cardboard boxes, 4 garbage bags, and a hose in the garage. Remove all of the garbage as a favor to your friend. Use rm -r garbage1 garbage2 garbage3 to get rid of all the garbage bags. Then, cd into each cardboard box and see which ones have garbage in them. Use rm -r on whichever boxes have garbage in them to delete them. Return to the main entrance. Use cd ../.. to go up 2 levels, then use cd main_entrance to enter the main entrance. Leave a note for your friend. Use touch goodbye_note.txt to create a file, then use nano goodbye_note.txt to add a message. There may be a hidden room in the house that was not previously explored. Look for it. Use cd .. to go up one level, then use ls -a to reveal all files/directories. It should reveal .hidden_basement. Enter the hidden basement with cd .hidden_basement , then list all files/directories with ls -a . This should reveal .hidden_stash. Reflection This project was a thorough introduction and exploration of the CLI for MacOS and Linux, and taught important commands such as cd , ls , and many more. The CLI is essential in networking environments since servers never have any kind of GUI to interact with. Instead, people interact with servers solely throught the CLI. Therefore, in order to work with IoT devices, servers, and basically anything related to networking, a strong grasp of how to use the CLI effectively is imperative. While working with a CLI was a bit intimidating at first, it was easy enough to get familiar with the commands and effectively carry out tasks.","title":"Command Line Interface"},{"location":"courses/ap_networking/cli/#command-line-interface","text":"","title":"Command Line Interface"},{"location":"courses/ap_networking/cli/#project-introduction","text":"This project was focused on learning the command line interface of Linux and MacOS. Since Linux is the backbone of networks, IoT systems, and most servers, a strong understanding of the CLI is essential for working with networks. The project included various small activities to teach the class about the CLI, including: Map the Maze Part I: Conceptual overview of file system and introduction to CLI commands. Ubuntu CLI Tutorial: Practice with using CLI commands in an Ubuntu VM Map the Maze Part II: Technical exploration of using CLI commands in Ubuntu, MacOS, and how to share files between a host and VM House Activity: Practice using CLI commands to navigate a \"house\" through the terminal to execute tasks using cd , rm , ls , and more. Reflection","title":"Project Introduction"},{"location":"courses/ap_networking/cli/#prerequisites","text":"In order to run Ubuntu on the M1 Mac minis in the computer lab, UTM was installed and Ubuntu was run inside a VM using Ubuntu with UTM, QEMU, and Apple Hypervisor for Apple Silicon. Also, MKDocs had to be installed on the Mac minis in order to build documentation and push it to GitHub. Unfortunately, simply running pip3 install mkdocs installed the mkdocs package installed it at ~/Library/Python/3.12, the user-specific folder that hosts packages tied to the system-wide python. However, by default, ZSH does not know about this folder, so the ZSH configuration profile had to be edited to point to this folder. Anytime mkdocs needed to be run, python3 -m mkdocs had to be specified rather than just being able to run mkdocs . To fix this issue, the process was: Type find ~/Library/Python -name mkdocs to find the specific path where mkdocs is installed. It should return /Users/*username*/Library/Python/3.xx/bin/mkdocs Open the ZSH configuration file with nano ~/.zshrc , then add this line: export PATH=\"$HOME/Library/Python/3.xx/bin:$PATH\" Refresh the ZSH profile with source ~/.zshrc Run mkdocs --version to confirm it works. It should return something like mkdocs, version 1.6.1 from /Users/*username*/Library/Python/3.xx/lib/python/site-packages/mkdocs (Python 3.xx) After completing these steps, MKDocs commands should be able to run by simply specifying mkdocs + command (build, serve, gh-deploy, etc.) rather than writing out python3 -m mkdocs . Although functionality remains unchanged, MKDocs is much easier and more convenient to work with after making these changes.","title":"Prerequisites"},{"location":"courses/ap_networking/cli/#map-the-maze-part-i","text":"This assignment was an introduction to the file system of a computer. Important terms learned in this assignment include: Term Definition Root Directory Very top of the file system Folder/Directory Container used to organize files and other folders File Single digital object that holds data in various formats; contains a name and an extension Path \"Address\" of a file or folder inside the file system; either an absolute or relative path Absolute Path Complete address of a file or directory (starting from root) Relative Path Location of a file or directory starting from the working directory","title":"Map the Maze Part I"},{"location":"courses/ap_networking/cli/#drawing-a-filesystem","text":"The first activity in this assignment was to draw out a file system with the root at the top, a home folder, 3 sub-folders, and 2 sample files. This section of the assignment was a simple introduction to the file system on a computer and helped in visualizing how a file system works.","title":"Drawing a Filesystem"},{"location":"courses/ap_networking/cli/#text-based-filesystem-partner-activity","text":"The next activity was to type up a file system similar to the one that was drawn earlier then to trade file systems with a partner and ask them how they would find specific files in the file system.","title":"Text-Based Filesystem &amp; Partner Activity"},{"location":"courses/ap_networking/cli/#macos-terminal-commands","text":"After learning about the file system, we learned about essential MacOS/Linux commands and their purposes for the CLI, such as: Command Purpose pwd Prints working directory (absolute path) ls Lists files and directories within the current directory cd Changes working directory to specified directory mkdir Makes a new directory within the current working directory `touch`` Makes a new file in the current working directory or an cp Copies specified files to a specified directory mv Moves specified files to a specified directory open Opens any file or folder within the directory if just a file/folder name is given, or any file on the computer if an absolute path is specified rm Permanently removes specified files rmdir Permanently removes specified directories","title":"MacOS Terminal Commands"},{"location":"courses/ap_networking/cli/#ubuntu-cli-tutorial","text":"After learning about essential Linux & MacOS CLI commands, we practiced using them in an Ubuntu VM to get familiar with both the commands and using Ubuntu. Following this Ubuntu tutorial made by Canonical , I practiced using the command line in Ubuntu. I used commands like ls , cd , rm , touch , cp , and a couple more.","title":"Ubuntu CLI Tutorial"},{"location":"courses/ap_networking/cli/#map-the-maze-part-ii","text":"This activity was completed mostly within the Ubuntu VM and involved creating files and directories, editing them with nano , and transferring files between the host and VM. The instructions for the activity were: Run pwd to show current directory Outputs /home/ubuntu (username is ubuntu in the VM) Use cd Documents to enter the documents folder and run pwd to show path Outputs /home/ubuntu/Documents Make a folder titled MazeGame in Documents and enter it with mkdir MazeGame and cd MazeGame Create 3 clue files with touch clue1.txt clue2.txt clue3.txt Add \"Congratulations! You found the first clue.\" to clue1.txt with nano clue1.txt Screenshot of the nano text editor for clue1.txt in the Ubuntu VM. Share a file with the host by copying clue1.txt to ~/hostshare/ with cp clue1.txt ~/hostshare/ On the first attempt, clue1.txt did not show up on the Mac anywhere after putting in in the hostshare folder in the VM. In order to enable file sharing between the host and VM, I needed to follow the following steps: Make a folder anywhere on the Mac, then go into UTM settings and set that folder as the shared directory for the VM In the VM, type sudo mount -t davfs http://127.0.0.1:9843/ ~/hostshare/ in order to set ~/hostshare as a shared directory between the host (M1 Mac mini) and the VM Restart the VM, then mount the shared disk inside UTM by selecting a shared folder Once these steps were completed, files were able to be shared between the host and VM through ~/hostshare in the VM and the folder on the Mac that was selected as a shared directory in UTM's settings.","title":"Map the Maze Part II"},{"location":"courses/ap_networking/cli/#house-sitting-activity","text":"The final activity in this project was the House Sitting Activity, where CLI commands were used to execute tasks within a \"house\" in the file system.","title":"House Sitting Activity"},{"location":"courses/ap_networking/cli/#prerequisites_1","text":"Before starting, open terminal, change directories to Downloads with cd Downloads , then clone the project by typing sudo git clone https://github.com/thewangclass/CK-Building-Content-Knowledge-Workshop . Once this is completed, the house can be explored by following the instructions.","title":"Prerequisites"},{"location":"courses/ap_networking/cli/#procedure","text":"Walk to the house and go inside. Use cd house Where can we go? ls returns bedroom1, bedroom2, garage, kitchen, and main_entrance Go inside the main entrance Use cd main_entrance See if there is anything around in the main entrance, such as instructions. ls returns instructions.txt, unopened_mail1.txt, unopened_mail2.txt, unopened_mail3.txt, and shoerack Open the instructions. Use cat instructions.txt to display the contents in the terminal. Leave the main entrance and go back to the house level. Use cd .. to go up one level in the file system in order to access other rooms Go inside the kitchen Use cd kitchen Check out what's inside the kitchen. ls returns apple, banana, cereal, crackers, donut, milk, orange \"Eat\" 2 items of food by removing them. Use rm -r apple donut to remove them. The -r argument after rm tells the rm command to act recursively and remove all of the arguments, not just the first one. You smell something, but you cannot see it. Find out what it is. Use ls -a in order to list all files, including hidden ones. This reveals everything from just writing ls , but also includes .rotten_bananas, a hidden file (files beginning with a period are hidden). Throw away the bananas. Use rm .rotten_bananas to delete the file Check the bedrooms to make sure everything is okay. Use cd .. to move up one level, then use cd bedroom1 to enter bedroom 1. Conduct a thorough search to look for anything unusual. Use ls -a to reveal everything, including hidden files. There's a hidden file titled .secret_diary.txt. Reveal the contents using cat .secret_diary.txt Now, enter bedroom 2 and explore it Use cd .. to move up one level then cd bedroom2 to enter the 2nd bedroom. Then, use ls -a to reveal all files. There was only regular items such as a chair, desk, and messy bed. Explore each item with ls -a [name] in order to list out the contents of each item. Desk should have a file titled search_desk.txt. The lights just went out and you are lost. Figure out where you currently are. Use pwd to print your location (directory) Navigate to the garage to figure out what is wrong with the lights. Use cd .. then cd garage to go to the garage. The lights suddenly come back. What is in the garage? Use ls -a to list the garage's contents. There are 3 cardboard boxes, 4 garbage bags, and a hose in the garage. Remove all of the garbage as a favor to your friend. Use rm -r garbage1 garbage2 garbage3 to get rid of all the garbage bags. Then, cd into each cardboard box and see which ones have garbage in them. Use rm -r on whichever boxes have garbage in them to delete them. Return to the main entrance. Use cd ../.. to go up 2 levels, then use cd main_entrance to enter the main entrance. Leave a note for your friend. Use touch goodbye_note.txt to create a file, then use nano goodbye_note.txt to add a message. There may be a hidden room in the house that was not previously explored. Look for it. Use cd .. to go up one level, then use ls -a to reveal all files/directories. It should reveal .hidden_basement. Enter the hidden basement with cd .hidden_basement , then list all files/directories with ls -a . This should reveal .hidden_stash.","title":"Procedure"},{"location":"courses/ap_networking/cli/#reflection","text":"This project was a thorough introduction and exploration of the CLI for MacOS and Linux, and taught important commands such as cd , ls , and many more. The CLI is essential in networking environments since servers never have any kind of GUI to interact with. Instead, people interact with servers solely throught the CLI. Therefore, in order to work with IoT devices, servers, and basically anything related to networking, a strong grasp of how to use the CLI effectively is imperative. While working with a CLI was a bit intimidating at first, it was easy enough to get familiar with the commands and effectively carry out tasks.","title":"Reflection"},{"location":"courses/ap_networking/component-cards-and-software-slips/","text":"Component Cards & Software Slips Project Introduction Component Cards and Software Slips was the first project of the year, and was designed to teach us about the various hardware and software components of a PC, and to teach us about how they all worked together. The project included various small activities to help us learn, including: Silent Signals Metal to Magic A Component Song Silent Signals Silent Signals was the first part of the project. In this activity, my partner and I each received a 3D printed card with a white side and a blue side, and our goal was to communicate various messages with each other solely with the cards, and without any kind of gesturing or speaking. From the start, we knew that we needed to establish some kind of standardized method of communication with each other. We mutually decided that to communicate numbers, we should use the card to tap the desk to represent the quantity of the number, and for boolean questions (yes/no, A/B, etc.) that we needed to assign one color to option 1 and the other color to option 2. Unfortunately, we couldn't talk, so we ended up picking different colors than each other. After trying out my system with partners, our new goal was to design a communication system to communicate the following information without gestures or speaking: The number 3 The month October \u201cYes\u201d to a yes/no question My plan for this was to: Start by tapping the table thrice to communicate the integer value of 3 Waiting a bit, then tapping the table 10 times to communicate October, since it's the 10th month Lastly, to communicate \"yes\" to a yes/no question, I would show the white side of the card. Although there's no way to guarantee that my partner would know white means yes, if you think about the card as an on/off switch, white would likely be \"on\" since it's light, and blue would be \"off\" since it's darker. Therefore, white would signify \"yes.\" This method required a bit of luck that my partner would understand what I was trying to communicate, since there was no way to actually talk with him to tell him what each color meant. Silent Signals Reflection The purpose of \"Silent Signals\" was to highlight the importance of a shared communication protocol. Similarly to how my partner and I were able to communicate more easily when we had a mutual understanding of what each others' signals meant, in order for machines to communicate effectively, they need to understand each others' protocols. Component Song The next part of Component Cards and Software Slips was the Component Song. Using ChatGPT, I generated song lyrics that described the multiple hardware and software components of a computer, and I then used Suno in order to have AI-generated vocals and instrumentals for the song. Song lyrics and link to song Component Song Reflection Creating the Component Song was a fun way to learn about the different parts of a computer, and helped me learn about what exactly each part does. Metal to Magic Metal to Magic was the main component of this project. In Metal to Magic, we formally learned about the many different hardware and software components of a PC, such as: Hardware Components Hardware Purpose CPU Executes instructions from programs RAM Temporarily stores data and instructions the CPU is currently using SSD/HDD Computer's long term data storage sytem GPU Processor specialized for parallel processing; useful for graphics processing and matrix multiplication Motherboard Main circuit board inside the computer; connects all hardware components and allows them to communicate via buses PSU Device that powers the system NIC Translates data between computer and network; enables WiFi capabilities Cooling System Keeps components cool in order to prevent overheating and thermal throttling I/O Devices Tools the user utilizes to interact with the computer (keyboard, microphone, mouse, camera, display, etc) Software Components Software Purpose Firmware/UEFI Starts the PC and hands off to OS; motherboard firmware Drivers Lets the OS talk to hardware OS Manages files, hardware, programs, UI, and much more Libraries/Runtimes Pre-written code for apps shared building blocks for apps Applications Programs for the user to interact with to complete tasks Hardware and Software Flowcharts After learning about what each component of a PC did, we needed to learn about how they all worked together. So, with a partner, I took cards with hardware and software components and arranged them to represent how individual components all interact with each other to get tasks done. We started off with keeping the hardware and software flowcharts separate, then at the end, trying to combine both hardware and software cards to visualize what exactly a computer does when printing out an essay. Hardware Flowchart Here, I tried to emphasize how virtually everything communicates through the motherboard, which is why I had the motherboard at the center and all of the components connected individually to the board. Software Flowchart Making the software component flowchart was a bit easier, since with software, there is a clearer hierarchy of the different layers, with the UEFI being at the lowest level and the runtimes and apps being at the highest level. Printing an Essay Flowchart (Hardware + Software) Before designing this flowchart, I thought through what exactly happened on my computer when I hit print, and did my best to represent that in my flowchart. Build a PC Activity With this knowledge about what the hardware and software components of a PC do and how they work together, a partner and I were given the task to upgrade a PC with a given budget to be most optimized for a task, such as gaming, video editing in 4K, AI training, etc. We chose to build a PC that was specialized for 4K video editing, and were given a budget of $1000 to upgrade along with a list of parts for purchase. Current Parts List CPU: mid-range 4-core processor RAM: 8 GB Storage: 256 GB SSD GPU: basic integrated graphics PSU: 500W basic model Standard cooling Basic NIC (network card) Motherboard that supports most modern upgrades Parts for Purchase Component Upgrade Option Cost CPU Mid-range 6-core processor $150 High-end 8-core processor $300 RAM 16 GB total RAM $150 32 GB total RAM $300 Storage 512 GB SSD $150 1 TB SSD $250 2 TB HDD (extra, for bulk storage) $100 GPU Mid-range graphics card (good for gaming, video) $250 High-end graphics card (best for gaming, ML) $400 Cooling System Enhanced air cooling $100 Liquid cooling system $200 NIC 2.5 Gbps network card $100 Other Extra case fans, RGB lighting, style upgrades $50 What we Decided to Do Before deciding anything immediately, my partner an I reflected on what exactly a video editing workflow demanded the most. We decided that the biggest limiting factor in our current PC build was the 8GB of RAM, since video editing consumes a lot of RAM. Although 32GB RAM would have been nice, we only had the budget to increase to 16GB, which is still enough for 4K editing (total spent: $150). Next, we upgraded the cooling system, since video editing often requires long exports, which often take multiple hours. This would inevitably generate a lot of heat, so maximum cooling was necessary to ensure that the sustained performance of the system was good. We went with the enhanced air cooling system along with extra case fans (total spent: $300). Next, we upgraded the GPU, since our current build only had a very weak integrated graphics chip. Video editing leans a lot on the GPU, and the current integrated graphics would make 4K video editing a nightmare. We went with the mid-range graphics card, since we didn't have the budget for a high-end graphics card (total: $550). After that, we upgraded the CPU to the high-end 8 core processor, because along with using the GPU a lot, video editing requires a CPU with strong multithreaded performance, so we went with the highest core-count CPU available (total: $850). Finally, with the remaining $150, we upgraded to the 512GB SSD, since video files take up a lot of storage. More storage would have been nice, but we didn't have the budget for anything else, and we figured that the editor could always use a NAS or cloud storage for storing older files (total: $1000). Metal to Magic Reflection Overall, Metal to Magic was very helpful in understanding not only what the individual components of a computer do, but also in explaining how the components work together. I learned about how standardized protocols are essential for machines to communicate with each other, and even for parts a machine to communicate with other parts.","title":"Component Cards & Software Slips"},{"location":"courses/ap_networking/component-cards-and-software-slips/#component-cards-software-slips","text":"","title":"Component Cards &amp; Software Slips"},{"location":"courses/ap_networking/component-cards-and-software-slips/#project-introduction","text":"Component Cards and Software Slips was the first project of the year, and was designed to teach us about the various hardware and software components of a PC, and to teach us about how they all worked together. The project included various small activities to help us learn, including: Silent Signals Metal to Magic A Component Song","title":"Project Introduction"},{"location":"courses/ap_networking/component-cards-and-software-slips/#silent-signals","text":"Silent Signals was the first part of the project. In this activity, my partner and I each received a 3D printed card with a white side and a blue side, and our goal was to communicate various messages with each other solely with the cards, and without any kind of gesturing or speaking. From the start, we knew that we needed to establish some kind of standardized method of communication with each other. We mutually decided that to communicate numbers, we should use the card to tap the desk to represent the quantity of the number, and for boolean questions (yes/no, A/B, etc.) that we needed to assign one color to option 1 and the other color to option 2. Unfortunately, we couldn't talk, so we ended up picking different colors than each other. After trying out my system with partners, our new goal was to design a communication system to communicate the following information without gestures or speaking: The number 3 The month October \u201cYes\u201d to a yes/no question My plan for this was to: Start by tapping the table thrice to communicate the integer value of 3 Waiting a bit, then tapping the table 10 times to communicate October, since it's the 10th month Lastly, to communicate \"yes\" to a yes/no question, I would show the white side of the card. Although there's no way to guarantee that my partner would know white means yes, if you think about the card as an on/off switch, white would likely be \"on\" since it's light, and blue would be \"off\" since it's darker. Therefore, white would signify \"yes.\" This method required a bit of luck that my partner would understand what I was trying to communicate, since there was no way to actually talk with him to tell him what each color meant. Silent Signals Reflection The purpose of \"Silent Signals\" was to highlight the importance of a shared communication protocol. Similarly to how my partner and I were able to communicate more easily when we had a mutual understanding of what each others' signals meant, in order for machines to communicate effectively, they need to understand each others' protocols.","title":"Silent Signals"},{"location":"courses/ap_networking/component-cards-and-software-slips/#component-song","text":"The next part of Component Cards and Software Slips was the Component Song. Using ChatGPT, I generated song lyrics that described the multiple hardware and software components of a computer, and I then used Suno in order to have AI-generated vocals and instrumentals for the song. Song lyrics and link to song Component Song Reflection Creating the Component Song was a fun way to learn about the different parts of a computer, and helped me learn about what exactly each part does.","title":"Component Song"},{"location":"courses/ap_networking/component-cards-and-software-slips/#metal-to-magic","text":"Metal to Magic was the main component of this project. In Metal to Magic, we formally learned about the many different hardware and software components of a PC, such as: Hardware Components Hardware Purpose CPU Executes instructions from programs RAM Temporarily stores data and instructions the CPU is currently using SSD/HDD Computer's long term data storage sytem GPU Processor specialized for parallel processing; useful for graphics processing and matrix multiplication Motherboard Main circuit board inside the computer; connects all hardware components and allows them to communicate via buses PSU Device that powers the system NIC Translates data between computer and network; enables WiFi capabilities Cooling System Keeps components cool in order to prevent overheating and thermal throttling I/O Devices Tools the user utilizes to interact with the computer (keyboard, microphone, mouse, camera, display, etc) Software Components Software Purpose Firmware/UEFI Starts the PC and hands off to OS; motherboard firmware Drivers Lets the OS talk to hardware OS Manages files, hardware, programs, UI, and much more Libraries/Runtimes Pre-written code for apps shared building blocks for apps Applications Programs for the user to interact with to complete tasks","title":"Metal to Magic"},{"location":"courses/ap_networking/component-cards-and-software-slips/#hardware-and-software-flowcharts","text":"After learning about what each component of a PC did, we needed to learn about how they all worked together. So, with a partner, I took cards with hardware and software components and arranged them to represent how individual components all interact with each other to get tasks done. We started off with keeping the hardware and software flowcharts separate, then at the end, trying to combine both hardware and software cards to visualize what exactly a computer does when printing out an essay.","title":"Hardware and Software Flowcharts"},{"location":"courses/ap_networking/component-cards-and-software-slips/#hardware-flowchart","text":"Here, I tried to emphasize how virtually everything communicates through the motherboard, which is why I had the motherboard at the center and all of the components connected individually to the board.","title":"Hardware Flowchart"},{"location":"courses/ap_networking/component-cards-and-software-slips/#software-flowchart","text":"Making the software component flowchart was a bit easier, since with software, there is a clearer hierarchy of the different layers, with the UEFI being at the lowest level and the runtimes and apps being at the highest level.","title":"Software Flowchart"},{"location":"courses/ap_networking/component-cards-and-software-slips/#printing-an-essay-flowchart-hardware-software","text":"Before designing this flowchart, I thought through what exactly happened on my computer when I hit print, and did my best to represent that in my flowchart.","title":"Printing an Essay Flowchart (Hardware + Software)"},{"location":"courses/ap_networking/component-cards-and-software-slips/#build-a-pc-activity","text":"With this knowledge about what the hardware and software components of a PC do and how they work together, a partner and I were given the task to upgrade a PC with a given budget to be most optimized for a task, such as gaming, video editing in 4K, AI training, etc. We chose to build a PC that was specialized for 4K video editing, and were given a budget of $1000 to upgrade along with a list of parts for purchase. Current Parts List CPU: mid-range 4-core processor RAM: 8 GB Storage: 256 GB SSD GPU: basic integrated graphics PSU: 500W basic model Standard cooling Basic NIC (network card) Motherboard that supports most modern upgrades Parts for Purchase Component Upgrade Option Cost CPU Mid-range 6-core processor $150 High-end 8-core processor $300 RAM 16 GB total RAM $150 32 GB total RAM $300 Storage 512 GB SSD $150 1 TB SSD $250 2 TB HDD (extra, for bulk storage) $100 GPU Mid-range graphics card (good for gaming, video) $250 High-end graphics card (best for gaming, ML) $400 Cooling System Enhanced air cooling $100 Liquid cooling system $200 NIC 2.5 Gbps network card $100 Other Extra case fans, RGB lighting, style upgrades $50 What we Decided to Do Before deciding anything immediately, my partner an I reflected on what exactly a video editing workflow demanded the most. We decided that the biggest limiting factor in our current PC build was the 8GB of RAM, since video editing consumes a lot of RAM. Although 32GB RAM would have been nice, we only had the budget to increase to 16GB, which is still enough for 4K editing (total spent: $150). Next, we upgraded the cooling system, since video editing often requires long exports, which often take multiple hours. This would inevitably generate a lot of heat, so maximum cooling was necessary to ensure that the sustained performance of the system was good. We went with the enhanced air cooling system along with extra case fans (total spent: $300). Next, we upgraded the GPU, since our current build only had a very weak integrated graphics chip. Video editing leans a lot on the GPU, and the current integrated graphics would make 4K video editing a nightmare. We went with the mid-range graphics card, since we didn't have the budget for a high-end graphics card (total: $550). After that, we upgraded the CPU to the high-end 8 core processor, because along with using the GPU a lot, video editing requires a CPU with strong multithreaded performance, so we went with the highest core-count CPU available (total: $850). Finally, with the remaining $150, we upgraded to the 512GB SSD, since video files take up a lot of storage. More storage would have been nice, but we didn't have the budget for anything else, and we figured that the editor could always use a NAS or cloud storage for storing older files (total: $1000).","title":"Build a PC Activity"},{"location":"courses/ap_networking/component-cards-and-software-slips/#metal-to-magic-reflection","text":"Overall, Metal to Magic was very helpful in understanding not only what the individual components of a computer do, but also in explaining how the components work together. I learned about how standardized protocols are essential for machines to communicate with each other, and even for parts a machine to communicate with other parts.","title":"Metal to Magic Reflection"},{"location":"courses/ap_networking/device-security/","text":"Implementing Security in Devices Table of Contents Project Introduction NIST and OWASP Guidelines Designing a Secure Password and Implementing it in Ubuntu Incorporating MFA in Ubuntu with Google Authenticator Patching Outdated Software in Ubuntu Reflection Project Introduction This project was focused on implementing different methods to secure devices such as creating/using password algorithms to create secure passwords, installing MFA tools in Ubuntu, patching outdated software, and incorporating NIST/OWASP guidelines. NIST and OWASP Guidelines NIST (National Institute of Standards and Technology) and OWASP (Open Worldwide Application Security Project) are both organizations that help develop standards and guidelines to help improve security, among other things. Both of these organizations release on creating strong passwords and securing devices. Common themes between the two organizations include: Use passwords that are both complex enough to be strong yet memorable enough to remember, as well as being lengthy Incorporate some sort of multi factor authentication (MFA) for services and devices, such as biometric authentication, verification with a one time password (OTP), or security questions Designing a Secure Password and Implementing it in Ubuntu Creating a Password Algorithm to Make a New Password Before this activity, the password for the Ubuntu VM is just \"ubuntu\". As one can imagine, \"ubuntu\" is not a very secure password! To generate a new password, I came up with the following algorithm, ensuring that a complex, long, yet memorable password could be used: Write out as many digits of \u03c0 as you can. The most you can easily write down is the base of the new password Then, split your name in half and add the first half to the front of the digits of \u03c0 and the second half to the end. If your name has an odd amount of characters, put the greater half at the start and the smaller half at the end. For example, if your name is Max and you know 10 digits of \u03c0, your password so far would be Ma3.141592653x. Then, replace all instances of lowercase a with @, lowercase i with !, lowercase e with 3, lowercase o with 0, lowercase s with 5, and lowercase l with 1. The final password for the example would be M@3.141592653x Implementing the New Password in Ubuntu To secure Ubuntu, the newly-generated password needed to be implemented. In order to change the password, the passwd command was run, which prompted for the current password (\"ubuntu\") then the new password (which was generated using the algorithm listed above). After entering the new password under the passwd command, the password should have changed (note: in the screenshot below, new password was mistyped a few times, which is why the computer printed \"sorry, passwords do not match\" a few times. The password did end up changing). In order to test to see if the new password works, sudo ls /root was run. The expected output is all of the contents of the /root directory. Since this command requires admin (sudo) privileges, it asked for the password. The newly-changed password was entered, and it worked, meaning that the passwd command successfully changed the password in Ubuntu, and that it works when running tasks requiring root access. Running the command returned snap, since that was the only item present in the /root directory. This indicates that the command worked, therefore the password is valid. Now, Ubuntu is more secure than before due to a much more complex password. Incorporating MFA in Ubuntu with Google Authenticator After the secure password was implemented, the next step in securing the Ubuntu VM was to implement some sort of MFA. Due to its widespread usage and relative simplicity, Google Authenticator was chosen as the method for implementing MFA. Google Authenticator works by generating a new TOTP (Temporary One Time Password) every 30 seconds with an algorithm. The Authenticator application and Google's server have the same algorithm, so when the code generated on the phone is used to authenticate, the account/service connects to Google's server to verify that the code is correct. If Google's server has the same code as the one that was inputted by the user, then the user is granted access to the account/service. To install Google Authenticator in Ubuntu, the following commands needed to be run: sudo apt update : Updates system packages to make sure the system is up to date, which helps prevent installation errors and ensures that the system is secure before setting up anything new. sudo apt install libpam-google-authenticator -y : Installs the Google Authenticator package for Ubuntu via the apt package manager and agrees to install the package with the -y flag. After installing the Google Authenticator package, the command google-authenticator was run to start the configuration process. To set it up, the following questions were answered: Prompt Answer Do you want authentication tokens to be time-based (y/n) y Update your .google_authenticator file? y Disallow multiple uses of the same token? y (Token valid for 30 seconds) Press Enter Enable rate-limiting? y After answering the questions, the terminal displayed a QR code which can be used to link Ubuntu to a Google Account for use with Google Authenticator. It also displayed recovery codes, which can be used in place of the TOTP generated in the app in case there is an issue with the app or the device is not connected to the internet. Those codes can only be used once. Additionally, it provided a secret key, which can also be used to link Ubuntu to the Google Authenticator app (in fact, the QR code displayed is just the secret key represented as a scannable code). Unfortunately, since the school iPads don't have the Google Authenticator, a TOTP website had to be used as a workaround ( the website should never be used as an actual method of security; it was used solely to verify that Google Authenticator is working. Never enter a secret key into any website ). To verify that Google Authenticator was working, the secret key was copied and pasted into the website, which enabled the website to generate a 6 digit verification code every 30 seconds. In Ubuntu, the google-authenticator command was re-run, and when it prompted to enter a code from the app, the code from the website was entered. It accepted the code, which means that the Google Authenticator installation works. The last step was to configure Ubuntu to require both a password and a code from Google Authenticator when logging in. The steps to do so were: Ensure PAM + keyboard-interactive are enabled in sshd. To do so, edit the SSH server configuration file with sudo nano /etc/ssh/sshd_config , find the line KbdInteractiveAuthentication no , and change it to KbdInteractiveAuthentication yes . Then, make sure UsePAM yes exists, and that it is set to \"yes\". Additionally, change #PasswordAuthentication no to #PasswordAuthentication yes if it isn't already set to \"yes\". Once these changes are made, save and exit the file, then restart the SSH server with sudo systemctl restart ssh . Add Google Authenticator to the SSH PAM stack. To do so, open the SSH PAM configuration file with sudo nano /etc/pam.d/sshd , then right below the header comment, add auth required pam_google_authenticator.so . Save and exit the file, then restart SSH again with sudo systemctl restart ssh . Test the login. To do so, SSH to the VM with ssh [username]@localhost (note: replace [username] with your actual Ubuntu username). It should prompt for botha password and verification code, indicating that Google Authenticator is set up for SSH. Patching Outdated Software in Ubuntu The last step in increasing the security of Ubuntu was to patch outdated software. Every computer needs regular patches to stay secure, since they fix bugs, security holes, and performance issues. This was done with the following steps: Check for available updates: To list out the packages that can be updated, sudo apt list --upgradable was run. On my specific VM, 1158 packages were outdated and had an upgrade available. Apply the updates (patches): To install the updates, sudo apt upgrade was run. This installs all the updates for the packages that were listed as \"upgradable\". Check the update history to verify that the update was installed: To verify that the update was installed, open the log file for apt with cat /var/log/apt/history.log . It returns the date, time, and list of packages that were updated. However, it is difficult to see a specific update due to the quantity of information in this log. Searching the log for a specific update to ensure a specific package has been updated: To search for updates on a specific date, the command grep \"yyyy-mm\" /var/log/apt/history.log can be used (replace yyyy-mm with a specific year and month) to show updates in a specific month. To show every package, software, and dependency that is installed on the system, grep \"Install:\" /var/log/apt/history.log was run. An example output is: Install: python3:amd64 (3.10.12-0ubuntu0.22.04.1, automatic) Part Meaning Install: This line lists newly installed software packages python3:amd64 The name of the package (Python 3 for 64-bit architecture (3.10.12-Oubuntu0.22.04.1) The version number of the package automatic Means the package was installed as a dependency (another program needed it) Example output from grep \"Install:\" /var/log/apt/history.log : The output is very long and unreadable. To search for a specific package, \"Install\" can be replaced with the package name (nano, firefox, etc.), meaning the command would like like this: grep \"firefox\" /var/lig/apt/history.log . To show recent updates, the last lines of history.log can be shown with tail -n 20 /var/log/apt/history.log (note: 20 can be replaced with the desired amount of lines (10, 20, 32, 67, 102, etc.)). Ensuring that automatic updates have been applied: Ubuntu schedules automatic updates. The command ls -l /var/lib/apt/periodic can be run to see when Ubuntu last ran an automatic update. Reflection In modern times, securing devices is more important than ever. As our lives become more reliant on digital tools, keeping our digital lives safe from hackers is of the utmost importance. Having secure passwords for devices and online accounts is one of the easiest ways to be protected from hackers, and everybody should consider making secure passwords. However, just having a secure password often is not enough to be safe. This is why MFA is vital, since in combination with a secure password, it makes it exceptionally difficult for a hacker to break into a system or account. Since most enterprise servers and systems are Ubuntu-based, learning how to implement these changes in Ubuntu is very helpful in many careers.","title":"Implementing Security for Devices"},{"location":"courses/ap_networking/device-security/#implementing-security-in-devices","text":"","title":"Implementing Security in Devices"},{"location":"courses/ap_networking/device-security/#table-of-contents","text":"","title":"Table of Contents"},{"location":"courses/ap_networking/device-security/#project-introduction","text":"","title":"Project Introduction"},{"location":"courses/ap_networking/device-security/#nist-and-owasp-guidelines","text":"","title":"NIST and OWASP Guidelines"},{"location":"courses/ap_networking/device-security/#designing-a-secure-password-and-implementing-it-in-ubuntu","text":"","title":"Designing a Secure Password and Implementing it in Ubuntu"},{"location":"courses/ap_networking/device-security/#incorporating-mfa-in-ubuntu-with-google-authenticator","text":"","title":"Incorporating MFA in Ubuntu with Google Authenticator"},{"location":"courses/ap_networking/device-security/#patching-outdated-software-in-ubuntu","text":"","title":"Patching Outdated Software in Ubuntu"},{"location":"courses/ap_networking/device-security/#reflection","text":"","title":"Reflection"},{"location":"courses/ap_networking/device-security/#project-introduction_1","text":"This project was focused on implementing different methods to secure devices such as creating/using password algorithms to create secure passwords, installing MFA tools in Ubuntu, patching outdated software, and incorporating NIST/OWASP guidelines.","title":"Project Introduction"},{"location":"courses/ap_networking/device-security/#nist-and-owasp-guidelines_1","text":"NIST (National Institute of Standards and Technology) and OWASP (Open Worldwide Application Security Project) are both organizations that help develop standards and guidelines to help improve security, among other things. Both of these organizations release on creating strong passwords and securing devices. Common themes between the two organizations include: Use passwords that are both complex enough to be strong yet memorable enough to remember, as well as being lengthy Incorporate some sort of multi factor authentication (MFA) for services and devices, such as biometric authentication, verification with a one time password (OTP), or security questions","title":"NIST and OWASP Guidelines"},{"location":"courses/ap_networking/device-security/#designing-a-secure-password-and-implementing-it-in-ubuntu_1","text":"","title":"Designing a Secure Password and Implementing it in Ubuntu"},{"location":"courses/ap_networking/device-security/#creating-a-password-algorithm-to-make-a-new-password","text":"Before this activity, the password for the Ubuntu VM is just \"ubuntu\". As one can imagine, \"ubuntu\" is not a very secure password! To generate a new password, I came up with the following algorithm, ensuring that a complex, long, yet memorable password could be used: Write out as many digits of \u03c0 as you can. The most you can easily write down is the base of the new password Then, split your name in half and add the first half to the front of the digits of \u03c0 and the second half to the end. If your name has an odd amount of characters, put the greater half at the start and the smaller half at the end. For example, if your name is Max and you know 10 digits of \u03c0, your password so far would be Ma3.141592653x. Then, replace all instances of lowercase a with @, lowercase i with !, lowercase e with 3, lowercase o with 0, lowercase s with 5, and lowercase l with 1. The final password for the example would be M@3.141592653x","title":"Creating a Password Algorithm to Make a New Password"},{"location":"courses/ap_networking/device-security/#implementing-the-new-password-in-ubuntu","text":"To secure Ubuntu, the newly-generated password needed to be implemented. In order to change the password, the passwd command was run, which prompted for the current password (\"ubuntu\") then the new password (which was generated using the algorithm listed above). After entering the new password under the passwd command, the password should have changed (note: in the screenshot below, new password was mistyped a few times, which is why the computer printed \"sorry, passwords do not match\" a few times. The password did end up changing). In order to test to see if the new password works, sudo ls /root was run. The expected output is all of the contents of the /root directory. Since this command requires admin (sudo) privileges, it asked for the password. The newly-changed password was entered, and it worked, meaning that the passwd command successfully changed the password in Ubuntu, and that it works when running tasks requiring root access. Running the command returned snap, since that was the only item present in the /root directory. This indicates that the command worked, therefore the password is valid. Now, Ubuntu is more secure than before due to a much more complex password.","title":"Implementing the New Password in Ubuntu"},{"location":"courses/ap_networking/device-security/#incorporating-mfa-in-ubuntu-with-google-authenticator_1","text":"After the secure password was implemented, the next step in securing the Ubuntu VM was to implement some sort of MFA. Due to its widespread usage and relative simplicity, Google Authenticator was chosen as the method for implementing MFA. Google Authenticator works by generating a new TOTP (Temporary One Time Password) every 30 seconds with an algorithm. The Authenticator application and Google's server have the same algorithm, so when the code generated on the phone is used to authenticate, the account/service connects to Google's server to verify that the code is correct. If Google's server has the same code as the one that was inputted by the user, then the user is granted access to the account/service. To install Google Authenticator in Ubuntu, the following commands needed to be run: sudo apt update : Updates system packages to make sure the system is up to date, which helps prevent installation errors and ensures that the system is secure before setting up anything new. sudo apt install libpam-google-authenticator -y : Installs the Google Authenticator package for Ubuntu via the apt package manager and agrees to install the package with the -y flag. After installing the Google Authenticator package, the command google-authenticator was run to start the configuration process. To set it up, the following questions were answered: Prompt Answer Do you want authentication tokens to be time-based (y/n) y Update your .google_authenticator file? y Disallow multiple uses of the same token? y (Token valid for 30 seconds) Press Enter Enable rate-limiting? y After answering the questions, the terminal displayed a QR code which can be used to link Ubuntu to a Google Account for use with Google Authenticator. It also displayed recovery codes, which can be used in place of the TOTP generated in the app in case there is an issue with the app or the device is not connected to the internet. Those codes can only be used once. Additionally, it provided a secret key, which can also be used to link Ubuntu to the Google Authenticator app (in fact, the QR code displayed is just the secret key represented as a scannable code). Unfortunately, since the school iPads don't have the Google Authenticator, a TOTP website had to be used as a workaround ( the website should never be used as an actual method of security; it was used solely to verify that Google Authenticator is working. Never enter a secret key into any website ). To verify that Google Authenticator was working, the secret key was copied and pasted into the website, which enabled the website to generate a 6 digit verification code every 30 seconds. In Ubuntu, the google-authenticator command was re-run, and when it prompted to enter a code from the app, the code from the website was entered. It accepted the code, which means that the Google Authenticator installation works. The last step was to configure Ubuntu to require both a password and a code from Google Authenticator when logging in. The steps to do so were: Ensure PAM + keyboard-interactive are enabled in sshd. To do so, edit the SSH server configuration file with sudo nano /etc/ssh/sshd_config , find the line KbdInteractiveAuthentication no , and change it to KbdInteractiveAuthentication yes . Then, make sure UsePAM yes exists, and that it is set to \"yes\". Additionally, change #PasswordAuthentication no to #PasswordAuthentication yes if it isn't already set to \"yes\". Once these changes are made, save and exit the file, then restart the SSH server with sudo systemctl restart ssh . Add Google Authenticator to the SSH PAM stack. To do so, open the SSH PAM configuration file with sudo nano /etc/pam.d/sshd , then right below the header comment, add auth required pam_google_authenticator.so . Save and exit the file, then restart SSH again with sudo systemctl restart ssh . Test the login. To do so, SSH to the VM with ssh [username]@localhost (note: replace [username] with your actual Ubuntu username). It should prompt for botha password and verification code, indicating that Google Authenticator is set up for SSH.","title":"Incorporating MFA in Ubuntu with Google Authenticator"},{"location":"courses/ap_networking/device-security/#patching-outdated-software-in-ubuntu_1","text":"The last step in increasing the security of Ubuntu was to patch outdated software. Every computer needs regular patches to stay secure, since they fix bugs, security holes, and performance issues. This was done with the following steps: Check for available updates: To list out the packages that can be updated, sudo apt list --upgradable was run. On my specific VM, 1158 packages were outdated and had an upgrade available. Apply the updates (patches): To install the updates, sudo apt upgrade was run. This installs all the updates for the packages that were listed as \"upgradable\". Check the update history to verify that the update was installed: To verify that the update was installed, open the log file for apt with cat /var/log/apt/history.log . It returns the date, time, and list of packages that were updated. However, it is difficult to see a specific update due to the quantity of information in this log. Searching the log for a specific update to ensure a specific package has been updated: To search for updates on a specific date, the command grep \"yyyy-mm\" /var/log/apt/history.log can be used (replace yyyy-mm with a specific year and month) to show updates in a specific month. To show every package, software, and dependency that is installed on the system, grep \"Install:\" /var/log/apt/history.log was run. An example output is: Install: python3:amd64 (3.10.12-0ubuntu0.22.04.1, automatic) Part Meaning Install: This line lists newly installed software packages python3:amd64 The name of the package (Python 3 for 64-bit architecture (3.10.12-Oubuntu0.22.04.1) The version number of the package automatic Means the package was installed as a dependency (another program needed it) Example output from grep \"Install:\" /var/log/apt/history.log : The output is very long and unreadable. To search for a specific package, \"Install\" can be replaced with the package name (nano, firefox, etc.), meaning the command would like like this: grep \"firefox\" /var/lig/apt/history.log . To show recent updates, the last lines of history.log can be shown with tail -n 20 /var/log/apt/history.log (note: 20 can be replaced with the desired amount of lines (10, 20, 32, 67, 102, etc.)). Ensuring that automatic updates have been applied: Ubuntu schedules automatic updates. The command ls -l /var/lib/apt/periodic can be run to see when Ubuntu last ran an automatic update.","title":"Patching Outdated Software in Ubuntu"},{"location":"courses/ap_networking/device-security/#reflection_1","text":"In modern times, securing devices is more important than ever. As our lives become more reliant on digital tools, keeping our digital lives safe from hackers is of the utmost importance. Having secure passwords for devices and online accounts is one of the easiest ways to be protected from hackers, and everybody should consider making secure passwords. However, just having a secure password often is not enough to be safe. This is why MFA is vital, since in combination with a secure password, it makes it exceptionally difficult for a hacker to break into a system or account. Since most enterprise servers and systems are Ubuntu-based, learning how to implement these changes in Ubuntu is very helpful in many careers.","title":"Reflection"},{"location":"courses/ap_networking/networking_data_movement/","text":"Data Movement and Types of Networks Project Introduction This project was focused on understanding how a LAN works, how data travels between devices on a LAN, and introducing binary, decimal, and hexadecimal numbers and their uses in networking applications. Planning and Design Technical Development Testing and Evaluation Reflection Planning and Design The main objectives for this project were to explore how Local Area Networks (LANs) enable communication between devices that are in the same environment (house, school, building, etc.), showcase how IP and MAC addresses are used to identify devices (as well as learning about their differences), and to learn to use ICMP tools to test connections and find details about devices on the LAN. Components of a LAN and Representing them as Parts of a City Component Purpose Analogy Endpoint Devices (Computers, Printers, Phones, etc. Endpoint Devices are devices that send or receive data across a network. They are the ones that use the network. Houses in the city who communicate with other houses Ethernet Cables and Wi-Fi The physical (Ethernet) or wireless (Wi-Fi) connections that allow data to move between devices on a network. Roads that interconnect everything Switch A device that connects multiple endpoint devices within the same network and directs Roundabout that guides traffic and ensures that everyone goes to the right location Router Post office that decides which mail should stay local (within LAN) and should be mailed to other cities (Internet) Data The letters and packages that people mail to each other within the city and outside the city Important LAN Terms Term Definition LAN (Local Area Network) A network that connects endpoint devices within 1 building/campus and lets them share printers, files, and internet connections efficiently over the LAN Host Any device (computer, printer, phone, etc.) that can send or receive data on the network. Each host has a unique IP address assigned by the router. Switch A device that connects multiple devices on the LAN. It works by learning the MAC address (hardware identifier unique to each NIC) of each device plugged in. When data comes in, the switch forwards it exclusively to the intended device. Router A device that connects the LAN to other networks and the Internet. It uses IP addresses to send incoming data to the intended device. Packet Segmented data that contains the sender's IP (return address), receiver's IP (destination), and the \"payload\" (the actual message/data). When packets arrive, the endpoint device reassembles it into complete data. IP Address Unique identifier for endpoint devices on a network. Different IP address ranges mean different things (192.168.x.x and 10.x.x.x vs 169.254.x.x) Diagram of My House's LAN In my house, almost everything is connected via Wi-Fi, except for the switch and Home Assistant Server that handles all of the smart home tasks in my house. Everything is directly connected to the router, which communicates with the internet and cloud services. OSI Model - The Seven Layers of Networking Networks are often represented by the OSI model, which consists of seven categories that encompass all networking-related tasks. They are: Layer Name Description Analogy 7 Application An email client, web browser, or any internet-connected application (Spotify, Adobe Creative Cloud, Safari, etc. Human-computer interaction layer. 6 Presentation Translates data (encryption, compression) Ensures data is in a usable form. 5 Session Manages the connection Maintains connections and is responsible for controlling parts and sessions. 4 Transport Breaks data into segments Transmits data using transmission protocols such as TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) 3 Network Routes packages using IP addresses Decides which physical path the data will take. 2 Data Link Transfers frames via MAC (media access control) addresses Defines the format of data on the network. 1 Physical Wires, signals, routers, switches, Wi-Fi Transmits raw bit streams over the physical medium. OSI Cards Diagram The following images showcase an activity about understanding how real-world examples are categorized into the OSI layers: First Attempt First attempt at matching OSI cards with example and ordering them correctly. Correct Organization Correct organization of OSI cards with their examples. OSI vs TCP/IP Model TCP/IP Layer Corresponding OSI Layers Functions Application 7 (Application), 6 (Presentation), 5 (Session) Apps, HTTP, FTP Transport 4 (Transport) TCP/UDP, data segmentation Internet 3 (Network) IP addressing, routing Network Access 2 (Data Link), 1 (Physical) Physical and Data Link -------------- -------------------------------------------- -------------------------- Representing Numbers with Different Bases To demonstrate how number bases work, cards representing base-10 (decimal), base-2 (binary), and base-5 were provided. The task was to represent different numerical values with the different bases. Base 10 501 = 5 * 10 2 + 0 * 10 1 + 1 * 10 0 = 500 + 0 + 1 = 401 473 = 4 * 10 2 + 7 * 10 1 + 3 * 10 0 = 400 + 70 + 3 = 473 324 = 3 * 10 2 + 2 * 10 1 + 4 * 10 0 = 300 + 20 + 4 = 324 Base 5 84 (Decimal) = 3 * 5 2 + 1 * 5 1 + 4 * 5 0 = 300 + 50 + 4 = 314 (Base-5) = 84 (Base-10) 37 (Decimal) = 1 * 5\u00b2 + 2 * 5\u00b9 + 2 * 5\u2070 = 25 + 10 + 2 = 122 (Base-5) = 37 (Base-10) Technical Development In this section of the project, an Ubuntu VM was used to apply and verify networking concepts in the CLI. Using Ubuntu to Convert Between Binary and Decimal Converting between binary and decimal by hand is very difficult and tedious. Thankfully, the bc CLI tool can be used to perform the conversion. To convert from binary to decimal, the command echo \"obase=10; ibase=2; [Insert Binary Number]\" | bc and echo \"obase=2; 45\" | bc can be used to convert from binary to decimal and from decimal to binary, respectively. Below is a breakdown of these commands: Part Meaning echo Prints text \"obase=10; ibase=2; 101101\" The conversion formula \u2014 it tells the calculator what number base to use. obase \u201cOutput base\u201d \u2014 the numbering system you want the result in. ibase \u201cInput base\u201d \u2014 the numbering system your starting number is in. bc The basic calculator program built into Ubuntu \u2014 it performs the conversion. Below is what these commands look like in the Ubuntu CLI: Representing Network Information as Hexadecimal and Binary Although decimal is easily readable by humans, computers process information in binary. Any time a computer works with decimal numbers, it first has to convert it to binary in order to do any operations with it. To see Ubuntu's IP address in binary, ipcalc must be installed with sudo apt install ipcalc -y . After installing it, run ipcalc [IP address] to display network information in binary. Since hexadecimal can represent up to the number 15 in each character, it can store more information in less space when compared with decimal and especially compared to binary. To view network information in hexadecimal form in Ubuntu, the command printf '%02X%02X%02X%02X\\n' 192 168 64 2 , where 192, 168, 64, and 2 should be replaced with the digits from your IP address (found with ifconfig ). The output was C0A84002. Breaking this down: C0 = 192 A8 = 168 40 = 64 02 = 2 Testing and Evaluation Reflection","title":"Networking and Data Movement"},{"location":"courses/ap_networking/networking_data_movement/#data-movement-and-types-of-networks","text":"","title":"Data Movement and Types of Networks"},{"location":"courses/ap_networking/networking_data_movement/#project-introduction","text":"This project was focused on understanding how a LAN works, how data travels between devices on a LAN, and introducing binary, decimal, and hexadecimal numbers and their uses in networking applications. Planning and Design Technical Development Testing and Evaluation Reflection","title":"Project Introduction"},{"location":"courses/ap_networking/networking_data_movement/#planning-and-design","text":"The main objectives for this project were to explore how Local Area Networks (LANs) enable communication between devices that are in the same environment (house, school, building, etc.), showcase how IP and MAC addresses are used to identify devices (as well as learning about their differences), and to learn to use ICMP tools to test connections and find details about devices on the LAN.","title":"Planning and Design"},{"location":"courses/ap_networking/networking_data_movement/#components-of-a-lan-and-representing-them-as-parts-of-a-city","text":"Component Purpose Analogy Endpoint Devices (Computers, Printers, Phones, etc. Endpoint Devices are devices that send or receive data across a network. They are the ones that use the network. Houses in the city who communicate with other houses Ethernet Cables and Wi-Fi The physical (Ethernet) or wireless (Wi-Fi) connections that allow data to move between devices on a network. Roads that interconnect everything Switch A device that connects multiple endpoint devices within the same network and directs Roundabout that guides traffic and ensures that everyone goes to the right location Router Post office that decides which mail should stay local (within LAN) and should be mailed to other cities (Internet) Data The letters and packages that people mail to each other within the city and outside the city","title":"Components of a LAN and Representing them as Parts of a City"},{"location":"courses/ap_networking/networking_data_movement/#important-lan-terms","text":"Term Definition LAN (Local Area Network) A network that connects endpoint devices within 1 building/campus and lets them share printers, files, and internet connections efficiently over the LAN Host Any device (computer, printer, phone, etc.) that can send or receive data on the network. Each host has a unique IP address assigned by the router. Switch A device that connects multiple devices on the LAN. It works by learning the MAC address (hardware identifier unique to each NIC) of each device plugged in. When data comes in, the switch forwards it exclusively to the intended device. Router A device that connects the LAN to other networks and the Internet. It uses IP addresses to send incoming data to the intended device. Packet Segmented data that contains the sender's IP (return address), receiver's IP (destination), and the \"payload\" (the actual message/data). When packets arrive, the endpoint device reassembles it into complete data. IP Address Unique identifier for endpoint devices on a network. Different IP address ranges mean different things (192.168.x.x and 10.x.x.x vs 169.254.x.x)","title":"Important LAN Terms"},{"location":"courses/ap_networking/networking_data_movement/#diagram-of-my-houses-lan","text":"In my house, almost everything is connected via Wi-Fi, except for the switch and Home Assistant Server that handles all of the smart home tasks in my house. Everything is directly connected to the router, which communicates with the internet and cloud services.","title":"Diagram of My House's LAN"},{"location":"courses/ap_networking/networking_data_movement/#osi-model-the-seven-layers-of-networking","text":"Networks are often represented by the OSI model, which consists of seven categories that encompass all networking-related tasks. They are: Layer Name Description Analogy 7 Application An email client, web browser, or any internet-connected application (Spotify, Adobe Creative Cloud, Safari, etc. Human-computer interaction layer. 6 Presentation Translates data (encryption, compression) Ensures data is in a usable form. 5 Session Manages the connection Maintains connections and is responsible for controlling parts and sessions. 4 Transport Breaks data into segments Transmits data using transmission protocols such as TCP (Transmission Control Protocol) and UDP (User Datagram Protocol) 3 Network Routes packages using IP addresses Decides which physical path the data will take. 2 Data Link Transfers frames via MAC (media access control) addresses Defines the format of data on the network. 1 Physical Wires, signals, routers, switches, Wi-Fi Transmits raw bit streams over the physical medium.","title":"OSI Model - The Seven Layers of Networking"},{"location":"courses/ap_networking/networking_data_movement/#osi-cards-diagram","text":"The following images showcase an activity about understanding how real-world examples are categorized into the OSI layers:","title":"OSI Cards Diagram"},{"location":"courses/ap_networking/networking_data_movement/#first-attempt","text":"First attempt at matching OSI cards with example and ordering them correctly.","title":"First Attempt"},{"location":"courses/ap_networking/networking_data_movement/#correct-organization","text":"Correct organization of OSI cards with their examples.","title":"Correct Organization"},{"location":"courses/ap_networking/networking_data_movement/#osi-vs-tcpip-model","text":"TCP/IP Layer Corresponding OSI Layers Functions Application 7 (Application), 6 (Presentation), 5 (Session) Apps, HTTP, FTP Transport 4 (Transport) TCP/UDP, data segmentation Internet 3 (Network) IP addressing, routing Network Access 2 (Data Link), 1 (Physical) Physical and Data Link -------------- -------------------------------------------- --------------------------","title":"OSI vs TCP/IP Model"},{"location":"courses/ap_networking/networking_data_movement/#representing-numbers-with-different-bases","text":"To demonstrate how number bases work, cards representing base-10 (decimal), base-2 (binary), and base-5 were provided. The task was to represent different numerical values with the different bases.","title":"Representing Numbers with Different Bases"},{"location":"courses/ap_networking/networking_data_movement/#base-10","text":"501 = 5 * 10 2 + 0 * 10 1 + 1 * 10 0 = 500 + 0 + 1 = 401 473 = 4 * 10 2 + 7 * 10 1 + 3 * 10 0 = 400 + 70 + 3 = 473 324 = 3 * 10 2 + 2 * 10 1 + 4 * 10 0 = 300 + 20 + 4 = 324","title":"Base 10"},{"location":"courses/ap_networking/networking_data_movement/#base-5","text":"84 (Decimal) = 3 * 5 2 + 1 * 5 1 + 4 * 5 0 = 300 + 50 + 4 = 314 (Base-5) = 84 (Base-10) 37 (Decimal) = 1 * 5\u00b2 + 2 * 5\u00b9 + 2 * 5\u2070 = 25 + 10 + 2 = 122 (Base-5) = 37 (Base-10)","title":"Base 5"},{"location":"courses/ap_networking/networking_data_movement/#technical-development","text":"In this section of the project, an Ubuntu VM was used to apply and verify networking concepts in the CLI.","title":"Technical Development"},{"location":"courses/ap_networking/networking_data_movement/#using-ubuntu-to-convert-between-binary-and-decimal","text":"Converting between binary and decimal by hand is very difficult and tedious. Thankfully, the bc CLI tool can be used to perform the conversion. To convert from binary to decimal, the command echo \"obase=10; ibase=2; [Insert Binary Number]\" | bc and echo \"obase=2; 45\" | bc can be used to convert from binary to decimal and from decimal to binary, respectively. Below is a breakdown of these commands: Part Meaning echo Prints text \"obase=10; ibase=2; 101101\" The conversion formula \u2014 it tells the calculator what number base to use. obase \u201cOutput base\u201d \u2014 the numbering system you want the result in. ibase \u201cInput base\u201d \u2014 the numbering system your starting number is in. bc The basic calculator program built into Ubuntu \u2014 it performs the conversion. Below is what these commands look like in the Ubuntu CLI:","title":"Using Ubuntu to Convert Between Binary and Decimal"},{"location":"courses/ap_networking/networking_data_movement/#representing-network-information-as-hexadecimal-and-binary","text":"Although decimal is easily readable by humans, computers process information in binary. Any time a computer works with decimal numbers, it first has to convert it to binary in order to do any operations with it. To see Ubuntu's IP address in binary, ipcalc must be installed with sudo apt install ipcalc -y . After installing it, run ipcalc [IP address] to display network information in binary. Since hexadecimal can represent up to the number 15 in each character, it can store more information in less space when compared with decimal and especially compared to binary. To view network information in hexadecimal form in Ubuntu, the command printf '%02X%02X%02X%02X\\n' 192 168 64 2 , where 192, 168, 64, and 2 should be replaced with the digits from your IP address (found with ifconfig ). The output was C0A84002. Breaking this down: C0 = 192 A8 = 168 40 = 64 02 = 2","title":"Representing Network Information as Hexadecimal and Binary"},{"location":"courses/ap_networking/networking_data_movement/#testing-and-evaluation","text":"","title":"Testing and Evaluation"},{"location":"courses/ap_networking/networking_data_movement/#reflection","text":"","title":"Reflection"},{"location":"courses/ap_networking/security-controls/","text":"Determining Security Controls for Devices Project Introduction This project was focused on securing physical devices, specifically, patching vulnerabilities, recognizing examples of phishing, and other similar skills. Hackers and other malicious actors are constantly trying to break into devices, therefore knowing how to secure a device is vital for both personal devices and in commercial settings. Planning and Design Technical Development Testing and Evaluation Reflection Planning and Design The main objectives for this project were to identify types of attacks and recommend security controls for devices. Cybersecurity Basics The main purpose of cybersecurity can be represented by the CIA triad: C onfidentiality: keeping information secret from malicious actors I ntegrity: keeping information trustworthy, uncorrupted, accurate, and ensuring it hasn't been tampered with A vailability: making sure that information and systems are available when needed Checking Ubuntu in UTM To ensure that Ubuntu is secure, it is vital to be on the latest release. To check the version, the command uname -a can be used, and should output an example similar to Linux ubuntu 5.15.0-87-generic #97-Ubuntu SMP Tue Oct 3 09:52:42 UTC 2023 aarch64 aarch64 aarch64 GNU/Linux . This output means that the system is running Ubuntu on a 64-bit ARM processor (makes sense since M1 is an ARM chip) with Linux Kernel Version 5.15 which was built on October 3, 2023. Checking MacOS A similar process can be applied to macOS, albeit, with a slightly different command. system_profiler SPSoftwareDataType can be used to output data such as the macOS version, kernel version, and the build number. On my M1 Pro MacBook Pro, it outputted System Version: macOS 26.1 (25B5042k) Kernel Version: Darwin 25.1.0 Boot Volume: Macintosh HD Boot Mode: Normal Computer Name: Raaj's MacBook Pro User Name: Raaj Thakur (raajthakur) Secure Virtual Memory: Enabled System Integrity Protection: Enabled Time since boot: 2 days, 12 hours, 44 minutes The main takeaways from these data is that the computer is running macOS 26.1 with Darwin 25.1.0 (Darwin is the kernel of Apple software (such as macOS, VisionOS, iOS, etc.)). Common Device Vulnerabilities Devices are very complex, and therefore have many different aspects that could be vulnerable if ignored. Common vulnerabilities include: Outdated OS: Outdated operating systems almost always have vulnerabilities which can be exploited by malicious actors. Weak Passwords: Weak passwords can easily be guessed, allowing malicious actors to access sensitive data such as financial information, medical records, and more. Open Ports: Ports are \"doors\" that let data in and out of a computer. More open ports are more access points that malicious actors can exploit to access data on a computer. Therefore, only ports required for functionality should be open, and unused ports should be closed. Common ports include: Port 80 = HTTP (hyper text transfer protocol) Port 443 = HTTPS (secure hyper text transfer protocol) Port 22 = SSH (secure shell) Port 25 = SMTP (simple mail transfer protocol) Port 110 = POP3 (retrieve mail) Port 143 = IMAP (mail on server) Port 3389 = RDP (remote desktop protocol) Port 53 = DNS (domain name system) Port 67 = DHCP (dynamic host configuration protocol) Unpatched Software: Unpatched software is similar to outdated operating systems, as older versions of software often have vulnerabilities which malicious actors can use to do bad things. Vulnerability Tracking (CVE) Vulnerabilities are in virtually every software, and it is essential that these vulnerabilities are discovered and patched before hackers can exploit them. They are tracked using CVE, a standardized system for identifying and naming known vulnerabilities. Each vulnerability is assigned a unique CVE ID. Social Engineering Attacks Humans are usually the weakest link of the security of a device. Millions of people are targeted every day by social engineering attacks, attacks by hackers that exploit human behavior to trick them into installing malware, giving away information, or allowing hackers to directly control a system. Types of attacks include: Phishing: Broad attacks where malicious actors send mass emails, texts, or other similar things to trick users into clicking a fraudulent link. Spear Phishing: More targeted version of phishing that targets a specific group or organization. Pretexting: When an attacker invents a story or identity to trick a victim to sending them money, sharing sensitive information, or granting access to a device. Baiting: Offering a prize to trick a victim into doing something that installs malware or sharing sensitive information. Tailgating: A physical tactic where a malicious actor follows an authorized person into a secure location, giving them access to sensitive data. Technical Development Recognizing and Updating Outdated Software In order to secure the VM, I checked the version of important softwares in Ubuntu, then either installed them if they weren't previously installed or updated them if they were outdated. Software Status What the Software Does OpenSSL Up to Date Encrypts network traffic Firefox Up to Date Web browser LibreOffice Outdated Office software (text, spreadsheets, slideshows, etc.) Python Up to Date Popular programming language that underpins many modern apps and programs Apache HTTP Server Not Installed HTTP server; important for hosting websites GIMP Not Installed Photo editing software Java Not Installed Programming language that underpins many programs OpenSSH Up to Date Package for the SSH protocol, important for direct communication between 2 devices Checking Open Ports Open ports can be a vulnerability in a system and can easily be secured by closing them if the port is not necessary. The open ports can be checked on Linudx with netstat -tuln . netstat is a CLI tool that shows network connections, routing tables, and open ports, and the -tuln argument tells netstat to show T CP connections ( t ), U DP connections ( u ), only ports that are l istening ( l ), and show port n umbers instead of service names ( n ). On my VM, ports 445, 139, 53, 22, 54, 9843, 631, 5353, 43433, 68, 137, 139, and 53918 were open. Setting up the Firewall (UFW) On Linux, a commonly used firewall is UFW (Uncomplicated Firewall). A firewall is akin to a security guard for a computer: it decides which ports should stay open and which should be locked. To use UFW, follow the following steps: Install it with sudo apt update && sudo apt upgrade , then sudo apt install ufw -y Check UFW's status with sudo ufw status If it returns inactive , then enable it with sudo ufw enable . At this point, UFW should be enabled Testing and Evaluation Testing for Disk Encryption in Ubuntu and macOS Disk encryption is a common method of securing devices. It makes data on the SSD/HDD unreadable by anything other than the computer that has the encryption key for the drive. Both Linux and macOS have their own encryption services: LUKS and FileVault, respectively. Testing Encryption on Linux lsblk -f can be run to see if the disk is encrypted in Ubuntu. If the output mentions drives formatted as ext4 or vfat, that means that LUKS is off, and if it returns the type of drive as crypto_LUKS, then the drive is encrypted. My system was not encrypted, indicated by the ext4 and vfat at the bottom of the output. Testing Encryption on macOS To check FileVault (disk encryption) status on macOS, run fdesetup status , which either returns \"FileVault is On\" or \"FileVault is Off\". Without encryption, someone could physically access a device's data by removing the SSD/HDD and plugging it into their own computer (this can't be done on modern Macs since their SSDs are soldered to the board). Reflection This project taught me about the many types of vulnerabilities in computers, how to secure devices, different types of social engineering attacks, and more. Through completing this project, I learned how to use the CLI to secure devices on both Linux and macOS, and about how to work with many different elements such as ports, firewalls, encryption, and more. I learned a lot about the dangers of having outdated software, and about CVE. Overall, this project provided a thorough overview of how to determine security controls for devices.","title":"Determining Security Controls for Devices"},{"location":"courses/ap_networking/security-controls/#determining-security-controls-for-devices","text":"","title":"Determining Security Controls for Devices"},{"location":"courses/ap_networking/security-controls/#project-introduction","text":"This project was focused on securing physical devices, specifically, patching vulnerabilities, recognizing examples of phishing, and other similar skills. Hackers and other malicious actors are constantly trying to break into devices, therefore knowing how to secure a device is vital for both personal devices and in commercial settings. Planning and Design Technical Development Testing and Evaluation Reflection","title":"Project Introduction"},{"location":"courses/ap_networking/security-controls/#planning-and-design","text":"The main objectives for this project were to identify types of attacks and recommend security controls for devices.","title":"Planning and Design"},{"location":"courses/ap_networking/security-controls/#cybersecurity-basics","text":"The main purpose of cybersecurity can be represented by the CIA triad: C onfidentiality: keeping information secret from malicious actors I ntegrity: keeping information trustworthy, uncorrupted, accurate, and ensuring it hasn't been tampered with A vailability: making sure that information and systems are available when needed","title":"Cybersecurity Basics"},{"location":"courses/ap_networking/security-controls/#checking-ubuntu-in-utm","text":"To ensure that Ubuntu is secure, it is vital to be on the latest release. To check the version, the command uname -a can be used, and should output an example similar to Linux ubuntu 5.15.0-87-generic #97-Ubuntu SMP Tue Oct 3 09:52:42 UTC 2023 aarch64 aarch64 aarch64 GNU/Linux . This output means that the system is running Ubuntu on a 64-bit ARM processor (makes sense since M1 is an ARM chip) with Linux Kernel Version 5.15 which was built on October 3, 2023.","title":"Checking Ubuntu in UTM"},{"location":"courses/ap_networking/security-controls/#checking-macos","text":"A similar process can be applied to macOS, albeit, with a slightly different command. system_profiler SPSoftwareDataType can be used to output data such as the macOS version, kernel version, and the build number. On my M1 Pro MacBook Pro, it outputted System Version: macOS 26.1 (25B5042k) Kernel Version: Darwin 25.1.0 Boot Volume: Macintosh HD Boot Mode: Normal Computer Name: Raaj's MacBook Pro User Name: Raaj Thakur (raajthakur) Secure Virtual Memory: Enabled System Integrity Protection: Enabled Time since boot: 2 days, 12 hours, 44 minutes The main takeaways from these data is that the computer is running macOS 26.1 with Darwin 25.1.0 (Darwin is the kernel of Apple software (such as macOS, VisionOS, iOS, etc.)).","title":"Checking MacOS"},{"location":"courses/ap_networking/security-controls/#common-device-vulnerabilities","text":"Devices are very complex, and therefore have many different aspects that could be vulnerable if ignored. Common vulnerabilities include: Outdated OS: Outdated operating systems almost always have vulnerabilities which can be exploited by malicious actors. Weak Passwords: Weak passwords can easily be guessed, allowing malicious actors to access sensitive data such as financial information, medical records, and more. Open Ports: Ports are \"doors\" that let data in and out of a computer. More open ports are more access points that malicious actors can exploit to access data on a computer. Therefore, only ports required for functionality should be open, and unused ports should be closed. Common ports include: Port 80 = HTTP (hyper text transfer protocol) Port 443 = HTTPS (secure hyper text transfer protocol) Port 22 = SSH (secure shell) Port 25 = SMTP (simple mail transfer protocol) Port 110 = POP3 (retrieve mail) Port 143 = IMAP (mail on server) Port 3389 = RDP (remote desktop protocol) Port 53 = DNS (domain name system) Port 67 = DHCP (dynamic host configuration protocol) Unpatched Software: Unpatched software is similar to outdated operating systems, as older versions of software often have vulnerabilities which malicious actors can use to do bad things.","title":"Common Device Vulnerabilities"},{"location":"courses/ap_networking/security-controls/#vulnerability-tracking-cve","text":"Vulnerabilities are in virtually every software, and it is essential that these vulnerabilities are discovered and patched before hackers can exploit them. They are tracked using CVE, a standardized system for identifying and naming known vulnerabilities. Each vulnerability is assigned a unique CVE ID.","title":"Vulnerability Tracking (CVE)"},{"location":"courses/ap_networking/security-controls/#social-engineering-attacks","text":"Humans are usually the weakest link of the security of a device. Millions of people are targeted every day by social engineering attacks, attacks by hackers that exploit human behavior to trick them into installing malware, giving away information, or allowing hackers to directly control a system. Types of attacks include: Phishing: Broad attacks where malicious actors send mass emails, texts, or other similar things to trick users into clicking a fraudulent link. Spear Phishing: More targeted version of phishing that targets a specific group or organization. Pretexting: When an attacker invents a story or identity to trick a victim to sending them money, sharing sensitive information, or granting access to a device. Baiting: Offering a prize to trick a victim into doing something that installs malware or sharing sensitive information. Tailgating: A physical tactic where a malicious actor follows an authorized person into a secure location, giving them access to sensitive data.","title":"Social Engineering Attacks"},{"location":"courses/ap_networking/security-controls/#technical-development","text":"","title":"Technical Development"},{"location":"courses/ap_networking/security-controls/#recognizing-and-updating-outdated-software","text":"In order to secure the VM, I checked the version of important softwares in Ubuntu, then either installed them if they weren't previously installed or updated them if they were outdated. Software Status What the Software Does OpenSSL Up to Date Encrypts network traffic Firefox Up to Date Web browser LibreOffice Outdated Office software (text, spreadsheets, slideshows, etc.) Python Up to Date Popular programming language that underpins many modern apps and programs Apache HTTP Server Not Installed HTTP server; important for hosting websites GIMP Not Installed Photo editing software Java Not Installed Programming language that underpins many programs OpenSSH Up to Date Package for the SSH protocol, important for direct communication between 2 devices","title":"Recognizing and Updating Outdated Software"},{"location":"courses/ap_networking/security-controls/#checking-open-ports","text":"Open ports can be a vulnerability in a system and can easily be secured by closing them if the port is not necessary. The open ports can be checked on Linudx with netstat -tuln . netstat is a CLI tool that shows network connections, routing tables, and open ports, and the -tuln argument tells netstat to show T CP connections ( t ), U DP connections ( u ), only ports that are l istening ( l ), and show port n umbers instead of service names ( n ). On my VM, ports 445, 139, 53, 22, 54, 9843, 631, 5353, 43433, 68, 137, 139, and 53918 were open.","title":"Checking Open Ports"},{"location":"courses/ap_networking/security-controls/#setting-up-the-firewall-ufw","text":"On Linux, a commonly used firewall is UFW (Uncomplicated Firewall). A firewall is akin to a security guard for a computer: it decides which ports should stay open and which should be locked. To use UFW, follow the following steps: Install it with sudo apt update && sudo apt upgrade , then sudo apt install ufw -y Check UFW's status with sudo ufw status If it returns inactive , then enable it with sudo ufw enable . At this point, UFW should be enabled","title":"Setting up the Firewall (UFW)"},{"location":"courses/ap_networking/security-controls/#testing-and-evaluation","text":"","title":"Testing and Evaluation"},{"location":"courses/ap_networking/security-controls/#testing-for-disk-encryption-in-ubuntu-and-macos","text":"Disk encryption is a common method of securing devices. It makes data on the SSD/HDD unreadable by anything other than the computer that has the encryption key for the drive. Both Linux and macOS have their own encryption services: LUKS and FileVault, respectively.","title":"Testing for Disk Encryption in Ubuntu and macOS"},{"location":"courses/ap_networking/security-controls/#testing-encryption-on-linux","text":"lsblk -f can be run to see if the disk is encrypted in Ubuntu. If the output mentions drives formatted as ext4 or vfat, that means that LUKS is off, and if it returns the type of drive as crypto_LUKS, then the drive is encrypted. My system was not encrypted, indicated by the ext4 and vfat at the bottom of the output.","title":"Testing Encryption on Linux"},{"location":"courses/ap_networking/security-controls/#testing-encryption-on-macos","text":"To check FileVault (disk encryption) status on macOS, run fdesetup status , which either returns \"FileVault is On\" or \"FileVault is Off\". Without encryption, someone could physically access a device's data by removing the SSD/HDD and plugging it into their own computer (this can't be done on modern Macs since their SSDs are soldered to the board).","title":"Testing Encryption on macOS"},{"location":"courses/ap_networking/security-controls/#reflection","text":"This project taught me about the many types of vulnerabilities in computers, how to secure devices, different types of social engineering attacks, and more. Through completing this project, I learned how to use the CLI to secure devices on both Linux and macOS, and about how to work with many different elements such as ports, firewalls, encryption, and more. I learned a lot about the dangers of having outdated software, and about CVE. Overall, this project provided a thorough overview of how to determine security controls for devices.","title":"Reflection"},{"location":"courses/ap_networking/troubleshooting/","text":"Troubleshooting Project Introduction This project was focused on troubleshooting various aspects of networks through CLI commands. Both MacOS and Ubuntu in a VM were used. Important Terminology Term Definition Wi-Fi Protocol that uses radio waves to wirelessly connect devices to a local network Ethernet Protocol that uses cables to connect devices to a local network Network Adapter Hardware that lets a computer communicate with the network (NIC in a PC) IP Address Identifiable address given to any device on a network Default Gateway (Router) Device that connects the local network to the internet. Metaphor: exit ramp connecting a neighborhood to a highway. DNS Domain Name System; translates website names to IP addresses Ping CLI command that tests communication between devices NAT/Shared Networking Network Address Translation; VM shares host's IP address Bridged Networking VM appears as its own device with a separate IP from the host Four Step Troubleshooting Workflow Test the Physical Connection Check if Wi-Fi is turned on or if Ethernet is plugged in Check Wi-Fi/Ethernet settings in MacOS/Windows/Linux Check the IP Address MacOS: Run ifconfig , then look for en0/en1 and make sure that at least one of them lists inet: 192.168.x.x or 10.x.x.x Linux: Run ip addr , then look for interfaces named like enpXsY (for example, enp0s3 or enp0s1 ), which are common on modern Linux systems, and make sure that at least one of them lists inet: 192.168.x.x or 10.x.x.x If it lists 169.254.x.x, that means that the device has a self-assigned IP address , meaning it likely can't connect to the internet Test Basic Reachability Ping a public server from Google or Cloudflare with ping -c 4 8.8.8.8 or ping -c 4 1.1.1.1 , respectively, to make sure that the computer can communicate with them If this works, then the computer can connect to the internet Test the DNS After confirming that ping -c 4 8.8.8.8 works, check the DNS with ping -c 4 google.com . 8.8.8.8 is Google's public DNS, meaning that when you connect to 8.8.8.8, you connect to google.com, and vice versa. If the computer can connect to the IP address (8.8.8.8) but not the domain name (google.com), then there is a DNS issue IP Range Meaning The type of IP address that is assigned to a device has a specific meaning. Below are common private IP address ranges and what they mean. IP Range What it Means Example 192.168.x.x Private IP common in home/school network; assigned by router/DHCP Common on Wi-Fi networks 10.x.x.x Private IP common in large organizations and VMs Ubuntu VM in Bridged mode 172.16.x.x \u2013 172.31.x.x Less common private IP Pretty rare, usually is assigned when there are a very large amount of devices on a network 169.254.x.x Self-assigned IP (device could not get IP from router) Happens if Wi-Fi is on but router is unresponsive or if computer cannot communicate with router for any reason Network Troubleshooting from MacOS CLI When troubleshooting networks on a Mac, vital commands to know are: - ifconfig : reveals IP address and other network information - ping : tests connection - route -n get default : outputs default gateway (router) information Network Troubleshooting from Linux CLI When troubleshooting networks on Linux, vital commands to know are: - ip addr : reveals IP address and other network information - ping : tests connection - ip route : outputs default gateway (router) information (preferred modern command) - netstat -rn : also outputs routing information, but may not be installed by default on modern Linux distributions Shared vs Bridged Network in UTM (Ubuntu) In UTM, the two major network modes are Shared and Bridged . While Shared mode shares the host device's IP address and appears as the host on the network, Bridged mode acts as its own separate computer with a unique IP address. Shared Mode Exploration I started the exploration with Shared mode. Running ip addr returned an IP address of 192.168.64.6 under enp0s1, which is standard behavior for a VM. The network adapter is circled in red, the IP address in blue, and the MAC address in green. Bridged Mode Exploration After exploring Shared mode, I powered down the VM, edited the VM's network settings from UTM, and set network mode to Bridged and selected Emulated Network to be en1 (since the Mac mini was on Wi-Fi, not Ethernet). Running ip addr in the Bridged VM returned an IP address of 192.168.1.132 under enp0s1, which is standard behavior for a VM. Notably, the IP address was different than it was under Shared mode, exhibiting how Bridged mode makes the router think that the VM is an individual computer. After testing the IP address, basic reachability needed to be tested. This was done with ping -c 4 8.8.8.8 (pings the Google public server 4 times). This did not work at first, but this was due to a firewall issue in Ubuntu. Running sudo ufw disable stopped the firewall and allowed Ubuntu to ping Google's server. Caution: Disabling the firewall with sudo ufw disable is not recommended in production environments, as it can expose your system to security risks. Only disable the firewall temporarily for troubleshooting, and re-enable it ( sudo ufw enable ) when finished. Additionally, the VM in Bridged mode could ping the Mac mini's IP address, since they act as 2 separate computers. The latency between the Mac mini and the VM was considerably lower than between the VM and Google (0.838 ms vs 12.694 ms), which makes sense since the Mac mini is on the same local network as the VM. Next, the DNS needed to be tested. Running ping -c 4 google.com returned virtually the exact same output as ping -c 4 8.8.8.8 (there was a very slight difference in average latency within margin of error), meaning that the DNS worked. Reflection This assignment provided a strong overview of how to troubleshoot networks from MacOS and Linux. Learning CLI tools to diagnose networks is extremely important in many settings, since virtually all networking equipment is accessible solely through a CLI. The 4 step workflow is used by virtually all professionals in their industry to troubleshoot networks, so learning those skills now is very valuable.","title":"Network Troubleshooting"},{"location":"courses/ap_networking/troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"courses/ap_networking/troubleshooting/#project-introduction","text":"This project was focused on troubleshooting various aspects of networks through CLI commands. Both MacOS and Ubuntu in a VM were used.","title":"Project Introduction"},{"location":"courses/ap_networking/troubleshooting/#important-terminology","text":"Term Definition Wi-Fi Protocol that uses radio waves to wirelessly connect devices to a local network Ethernet Protocol that uses cables to connect devices to a local network Network Adapter Hardware that lets a computer communicate with the network (NIC in a PC) IP Address Identifiable address given to any device on a network Default Gateway (Router) Device that connects the local network to the internet. Metaphor: exit ramp connecting a neighborhood to a highway. DNS Domain Name System; translates website names to IP addresses Ping CLI command that tests communication between devices NAT/Shared Networking Network Address Translation; VM shares host's IP address Bridged Networking VM appears as its own device with a separate IP from the host","title":"Important Terminology"},{"location":"courses/ap_networking/troubleshooting/#four-step-troubleshooting-workflow","text":"Test the Physical Connection Check if Wi-Fi is turned on or if Ethernet is plugged in Check Wi-Fi/Ethernet settings in MacOS/Windows/Linux Check the IP Address MacOS: Run ifconfig , then look for en0/en1 and make sure that at least one of them lists inet: 192.168.x.x or 10.x.x.x Linux: Run ip addr , then look for interfaces named like enpXsY (for example, enp0s3 or enp0s1 ), which are common on modern Linux systems, and make sure that at least one of them lists inet: 192.168.x.x or 10.x.x.x If it lists 169.254.x.x, that means that the device has a self-assigned IP address , meaning it likely can't connect to the internet Test Basic Reachability Ping a public server from Google or Cloudflare with ping -c 4 8.8.8.8 or ping -c 4 1.1.1.1 , respectively, to make sure that the computer can communicate with them If this works, then the computer can connect to the internet Test the DNS After confirming that ping -c 4 8.8.8.8 works, check the DNS with ping -c 4 google.com . 8.8.8.8 is Google's public DNS, meaning that when you connect to 8.8.8.8, you connect to google.com, and vice versa. If the computer can connect to the IP address (8.8.8.8) but not the domain name (google.com), then there is a DNS issue","title":"Four Step Troubleshooting Workflow"},{"location":"courses/ap_networking/troubleshooting/#ip-range-meaning","text":"The type of IP address that is assigned to a device has a specific meaning. Below are common private IP address ranges and what they mean. IP Range What it Means Example 192.168.x.x Private IP common in home/school network; assigned by router/DHCP Common on Wi-Fi networks 10.x.x.x Private IP common in large organizations and VMs Ubuntu VM in Bridged mode 172.16.x.x \u2013 172.31.x.x Less common private IP Pretty rare, usually is assigned when there are a very large amount of devices on a network 169.254.x.x Self-assigned IP (device could not get IP from router) Happens if Wi-Fi is on but router is unresponsive or if computer cannot communicate with router for any reason","title":"IP Range Meaning"},{"location":"courses/ap_networking/troubleshooting/#network-troubleshooting-from-macos-cli","text":"When troubleshooting networks on a Mac, vital commands to know are: - ifconfig : reveals IP address and other network information - ping : tests connection - route -n get default : outputs default gateway (router) information","title":"Network Troubleshooting from MacOS CLI"},{"location":"courses/ap_networking/troubleshooting/#network-troubleshooting-from-linux-cli","text":"When troubleshooting networks on Linux, vital commands to know are: - ip addr : reveals IP address and other network information - ping : tests connection - ip route : outputs default gateway (router) information (preferred modern command) - netstat -rn : also outputs routing information, but may not be installed by default on modern Linux distributions","title":"Network Troubleshooting from Linux CLI"},{"location":"courses/ap_networking/troubleshooting/#shared-vs-bridged-network-in-utm-ubuntu","text":"In UTM, the two major network modes are Shared and Bridged . While Shared mode shares the host device's IP address and appears as the host on the network, Bridged mode acts as its own separate computer with a unique IP address.","title":"Shared vs Bridged Network in UTM (Ubuntu)"},{"location":"courses/ap_networking/troubleshooting/#shared-mode-exploration","text":"I started the exploration with Shared mode. Running ip addr returned an IP address of 192.168.64.6 under enp0s1, which is standard behavior for a VM. The network adapter is circled in red, the IP address in blue, and the MAC address in green.","title":"Shared Mode Exploration"},{"location":"courses/ap_networking/troubleshooting/#bridged-mode-exploration","text":"After exploring Shared mode, I powered down the VM, edited the VM's network settings from UTM, and set network mode to Bridged and selected Emulated Network to be en1 (since the Mac mini was on Wi-Fi, not Ethernet). Running ip addr in the Bridged VM returned an IP address of 192.168.1.132 under enp0s1, which is standard behavior for a VM. Notably, the IP address was different than it was under Shared mode, exhibiting how Bridged mode makes the router think that the VM is an individual computer. After testing the IP address, basic reachability needed to be tested. This was done with ping -c 4 8.8.8.8 (pings the Google public server 4 times). This did not work at first, but this was due to a firewall issue in Ubuntu. Running sudo ufw disable stopped the firewall and allowed Ubuntu to ping Google's server. Caution: Disabling the firewall with sudo ufw disable is not recommended in production environments, as it can expose your system to security risks. Only disable the firewall temporarily for troubleshooting, and re-enable it ( sudo ufw enable ) when finished. Additionally, the VM in Bridged mode could ping the Mac mini's IP address, since they act as 2 separate computers. The latency between the Mac mini and the VM was considerably lower than between the VM and Google (0.838 ms vs 12.694 ms), which makes sense since the Mac mini is on the same local network as the VM. Next, the DNS needed to be tested. Running ping -c 4 google.com returned virtually the exact same output as ping -c 4 8.8.8.8 (there was a very slight difference in average latency within margin of error), meaning that the DNS worked.","title":"Bridged Mode Exploration"},{"location":"courses/ap_networking/troubleshooting/#reflection","text":"This assignment provided a strong overview of how to troubleshoot networks from MacOS and Linux. Learning CLI tools to diagnose networks is extremely important in many settings, since virtually all networking equipment is accessible solely through a CLI. The 4 step workflow is used by virtually all professionals in their industry to troubleshoot networks, so learning those skills now is very valuable.","title":"Reflection"},{"location":"courses/civil_engineering/","text":"","title":"Overview"},{"location":"courses/civil_engineering/bridge_building_and_testing/","text":"","title":"Bridge Building and Testing"},{"location":"courses/civil_engineering/water_turbidity/","text":"","title":"Water Turbidity Testing"},{"location":"courses/civil_engineering/windmill_optimization/","text":"","title":"Windmill Design and Optimization"},{"location":"courses/data_analytics/","text":"","title":"Overview"},{"location":"courses/data_analytics/anova/","text":"","title":"ANOVA"},{"location":"courses/data_analytics/bootstrapping/","text":"","title":"Bootstrapping"},{"location":"courses/data_analytics/data_cleaning/","text":"","title":"Data Cleaning"},{"location":"courses/data_analytics/excel/","text":"","title":"Excel"},{"location":"courses/data_analytics/machine_learning/","text":"","title":"Machine Learning"},{"location":"courses/data_analytics/python/","text":"","title":"Python"},{"location":"courses/engineering_1/","text":"","title":"Overview"},{"location":"courses/engineering_1/3d_printing/","text":"","title":"Plane and Simple"},{"location":"courses/engineering_1/box/","text":"","title":"Thinking Out of the Box"},{"location":"courses/engineering_1/cold_solder/","text":"","title":"A Cold Solder"},{"location":"courses/engineering_1/final_project/","text":"","title":"Final Project"},{"location":"courses/engineering_1/grab_a_byte/","text":"","title":"Grab a Byte"},{"location":"courses/engineering_1/keychain/","text":"","title":"Easily Suede"},{"location":"courses/engineering_1/ohm_depot/","text":"","title":"The Ohm Depot"},{"location":"courses/engineering_2/","text":"","title":"Overview"},{"location":"courses/engineering_2/cutting_board/","text":"","title":"Board to be Wild"},{"location":"courses/engineering_2/final_project/","text":"","title":"Final Project"},{"location":"courses/engineering_2/fusion360/","text":"","title":"Deep Dive into Fusion 360"},{"location":"courses/engineering_2/milling_about/","text":"","title":"Milling About"},{"location":"courses/engineering_2/pressing_charges/","text":"","title":"Pressing Charges"},{"location":"courses/senior_engineering/","text":"Honors Advanced Topics in Engineering Welcome to my documentation for the Advanced Topics in Engineering (Honors) course for the '25 - '26 school year. Projects Capstone Project Daily Log Pen Owl PCB Milling Course Overview Advanced Topics in Engineering is a senior-only course where students can work on a capstone project throughout the whole year. In the class, I decided to work on a custom-designed drone with advanced AI capabilities (see more under capstone project page ).","title":"Overview"},{"location":"courses/senior_engineering/#honors-advanced-topics-in-engineering","text":"Welcome to my documentation for the Advanced Topics in Engineering (Honors) course for the '25 - '26 school year.","title":"Honors Advanced Topics in Engineering"},{"location":"courses/senior_engineering/#projects","text":"Capstone Project Daily Log Pen Owl PCB Milling","title":"Projects"},{"location":"courses/senior_engineering/#course-overview","text":"Advanced Topics in Engineering is a senior-only course where students can work on a capstone project throughout the whole year. In the class, I decided to work on a custom-designed drone with advanced AI capabilities (see more under capstone project page ).","title":"Course Overview"},{"location":"courses/senior_engineering/capstone/","text":"Capstone For the majority of the year, I worked towards completing my capstone project: a fully custom-designed 3D printed drone with custom electronics and AI-powered object classification, pose tracking, facial recognition, and more. Navigation Build Goals From the start, I wanted my drone to do the following: Have a long battery life Be able to record video in at least 1080p Have high processing power for AI-powered tasks Custom design as much as possible Part Selection The first step of making the drone was to figure out what parts I wanted to use. I had to consider many questions, such as: - What purpose will the drone be made for (racing, cinematography, autonomous missions, etc.)? - How big will the drone be? - What firmware will it use (ArduPilot, Betaflight, etc.)? After considering many factors, I decided that I wanted to prioritize having a long flight time and powerful computers for autonomous missions. Those two choices meant that I would have to use a very large battery (meaning I would need a large drone to match), and that I need to use ArduPilot due to its support for GPS as well as a companion computer (more on this under the firmware section). I did some more research on drones, and I knew I wanted to build a drone with 7\" propellers (I ended up changing to 9\"), since it would allow me to support a chassis large enough to house advanced electronics and a very large battery. For that size, I saw that 6S (6 cell) LiPo batteries were most popular in the community due to their high voltage (up to 25.2V) which allows for the drone to be more efficient. I settled on the Ovonic 4500 mAh 6S LiPo 100C XT90 Battery , since it had a very large capacity (99.9 wh!), a very high discharge rate, a bulky XT90 connector to allow for high power draw, and it was 6S. After choosing the battery, I had to choose the motors, ESC, and electronic components. Since I chose a high-voltage battery, I went with relatively low 1050KV motors made by BrotherHobby. I saw good reviews about these online and they are made of high quality materials, which is why I chose them. The ESC is also made by BrotherHobby. It's a 4 in 1 ESC with support up to a 6S battery and can provide 65A per motor. I chose it since it had good reviews and was by far the cheapest ESC from a legitimate brand that could provide 65A per motor. For the electronic components, I needed to ensure that they could support ArduPilot, and that I chose a comprehensive suite of sensors to allow for autonomous flight. For the MCU, I chose the STM32F767ZIT6 since it is powerful and has ample I/O for all of the sensors. For the sensors, I chose the ICM 29048 (IMU), LIS2MDL (magnetometer), LPS22HB (barometer), and NEO-M9N (GPS). I found boards from Adafruit at competitive prices that featured the sensors, power management systems (capacitors, step downs, resistors, etc.), along with a STEMMA QT connector for easy I2C connectivity. Insted of soldering the extremely tiny sensors directly to the board, I decided to go with these Adafruit boards to reduce complexity and increase reliability. The NEO M9N is large enough where I can solder it myself, so I bought the bare chip and added the power management system for the NEO M9N directly to the board (more on this under the Electronics Architecture section). Additionally, I wanted a separate computer to drive the video recording and AI aspect. From the start, I knew that I wanted to use a Raspberry Pi 5 with the Raspberry Pi AI Hat+, capable of 26 TOPS. This combination allows for very powerful edge AI capabilities with high power efficiency, meaning that the drone can do real-time AI calculations in the air without drawing too much power. After all this consideration, I ended up with a very high end parts list that would create a drone with very powerful capabilities. The next step was to design the chassis . Chassis Design The first component I designed was the chassis. Originally, I wanted to use the Source One , an open source drone chassis supporting up to 7\" props. However, in its standard form, it had nowhere near enough space to fit my large battery, a Raspberry Pi 5, a camera, and all of the components for the flight controller (the board was not designed at this point). So, I downloaded the STEP files into Onshape and made significant changes to allow for the battery to fit. However, after printing it out, I realized that the drone is far too heavy and that the chassis is too complicated with too many parts. Additionally, I realized that for the weight of the components, I would need bigger propellers. I looked at the website for the motors, and it said that they support up to 9\" propellers, so I decided to switch. Instead of modifying the chassis more to be stiffer and to support bigger props, I decided to start fresh with a clean sheet design. I wanted to keep the design as simple as possible and to make sure that it would support the larger propellers. PCB Design Electronics Architecture Firmware Assembly TBD Testing and Calibration TBD Next Steps TBD","title":"Capstone Project"},{"location":"courses/senior_engineering/capstone/#capstone","text":"For the majority of the year, I worked towards completing my capstone project: a fully custom-designed 3D printed drone with custom electronics and AI-powered object classification, pose tracking, facial recognition, and more.","title":"Capstone"},{"location":"courses/senior_engineering/capstone/#navigation","text":"","title":"Navigation"},{"location":"courses/senior_engineering/capstone/#build-goals","text":"From the start, I wanted my drone to do the following: Have a long battery life Be able to record video in at least 1080p Have high processing power for AI-powered tasks Custom design as much as possible","title":"Build Goals"},{"location":"courses/senior_engineering/capstone/#part-selection","text":"The first step of making the drone was to figure out what parts I wanted to use. I had to consider many questions, such as: - What purpose will the drone be made for (racing, cinematography, autonomous missions, etc.)? - How big will the drone be? - What firmware will it use (ArduPilot, Betaflight, etc.)? After considering many factors, I decided that I wanted to prioritize having a long flight time and powerful computers for autonomous missions. Those two choices meant that I would have to use a very large battery (meaning I would need a large drone to match), and that I need to use ArduPilot due to its support for GPS as well as a companion computer (more on this under the firmware section). I did some more research on drones, and I knew I wanted to build a drone with 7\" propellers (I ended up changing to 9\"), since it would allow me to support a chassis large enough to house advanced electronics and a very large battery. For that size, I saw that 6S (6 cell) LiPo batteries were most popular in the community due to their high voltage (up to 25.2V) which allows for the drone to be more efficient. I settled on the Ovonic 4500 mAh 6S LiPo 100C XT90 Battery , since it had a very large capacity (99.9 wh!), a very high discharge rate, a bulky XT90 connector to allow for high power draw, and it was 6S. After choosing the battery, I had to choose the motors, ESC, and electronic components. Since I chose a high-voltage battery, I went with relatively low 1050KV motors made by BrotherHobby. I saw good reviews about these online and they are made of high quality materials, which is why I chose them. The ESC is also made by BrotherHobby. It's a 4 in 1 ESC with support up to a 6S battery and can provide 65A per motor. I chose it since it had good reviews and was by far the cheapest ESC from a legitimate brand that could provide 65A per motor. For the electronic components, I needed to ensure that they could support ArduPilot, and that I chose a comprehensive suite of sensors to allow for autonomous flight. For the MCU, I chose the STM32F767ZIT6 since it is powerful and has ample I/O for all of the sensors. For the sensors, I chose the ICM 29048 (IMU), LIS2MDL (magnetometer), LPS22HB (barometer), and NEO-M9N (GPS). I found boards from Adafruit at competitive prices that featured the sensors, power management systems (capacitors, step downs, resistors, etc.), along with a STEMMA QT connector for easy I2C connectivity. Insted of soldering the extremely tiny sensors directly to the board, I decided to go with these Adafruit boards to reduce complexity and increase reliability. The NEO M9N is large enough where I can solder it myself, so I bought the bare chip and added the power management system for the NEO M9N directly to the board (more on this under the Electronics Architecture section). Additionally, I wanted a separate computer to drive the video recording and AI aspect. From the start, I knew that I wanted to use a Raspberry Pi 5 with the Raspberry Pi AI Hat+, capable of 26 TOPS. This combination allows for very powerful edge AI capabilities with high power efficiency, meaning that the drone can do real-time AI calculations in the air without drawing too much power. After all this consideration, I ended up with a very high end parts list that would create a drone with very powerful capabilities. The next step was to design the chassis .","title":"Part Selection"},{"location":"courses/senior_engineering/capstone/#chassis-design","text":"The first component I designed was the chassis. Originally, I wanted to use the Source One , an open source drone chassis supporting up to 7\" props. However, in its standard form, it had nowhere near enough space to fit my large battery, a Raspberry Pi 5, a camera, and all of the components for the flight controller (the board was not designed at this point). So, I downloaded the STEP files into Onshape and made significant changes to allow for the battery to fit. However, after printing it out, I realized that the drone is far too heavy and that the chassis is too complicated with too many parts. Additionally, I realized that for the weight of the components, I would need bigger propellers. I looked at the website for the motors, and it said that they support up to 9\" propellers, so I decided to switch. Instead of modifying the chassis more to be stiffer and to support bigger props, I decided to start fresh with a clean sheet design. I wanted to keep the design as simple as possible and to make sure that it would support the larger propellers.","title":"Chassis Design"},{"location":"courses/senior_engineering/capstone/#pcb-design","text":"","title":"PCB Design"},{"location":"courses/senior_engineering/capstone/#electronics-architecture","text":"","title":"Electronics Architecture"},{"location":"courses/senior_engineering/capstone/#firmware","text":"","title":"Firmware"},{"location":"courses/senior_engineering/capstone/#assembly","text":"TBD","title":"Assembly"},{"location":"courses/senior_engineering/capstone/#testing-and-calibration","text":"TBD","title":"Testing and Calibration"},{"location":"courses/senior_engineering/capstone/#next-steps","text":"TBD","title":"Next Steps"},{"location":"courses/senior_engineering/daily_log/","text":"Honors Advanced Topics in Engineering Daily Log Welcome to my daily log for engineering! Here, I will outline what I do every day in class. Navigation September October November December January February March April May June September 09.03.2025 Today, I continued work on my wooden pen. I took my two blocks of wood and turned them on a lathe. I took a chisel and removed material until the blocks were cylindrical, and when they got to the desired thickness, I used fine grit sandpaper to smooth the two blocks. Now, I have the two wooden components for my pen ready, and now, I can assemble the pen and do all of the finishing touches next class. 09.04.2025 Today, I finished my pen. I started off by using the pen press to: Press the pen tip into the bottom end of the lower barrel Press the ink chamber into the top end of the lower barrel Press the clip assembly into the top end of the upper barrel Once I pressed these components, I could assemble the main sections together. I screwed the ink refill into the ink chamber, slid the ring onto the chamber above the lower barrel, and slid the upper barrel above the ring. Once I did that, my pen was done, and it wrote super well, along with looking very cool. 09.05.2025 Today, I did some research and work on my capstone project. My goal is to assemble the board as soon as possible, so today, I practiced soldering random components to practice boards to prepare for soldering intricate components on the board. 09.08.2025 Today, I researched more about how to configure ArduPilot for a custom board. I decided that I would have to compile ArduPilot from the source code with a custom hwdef.dat file for my specific hardware configuration. From the start, I knew that I wanted to do as much as possible in VSCode, as I am very familiar with it. After doing some researching, I discovered that ArduPilot provides a VSCode integration which allows you to configure and flash ArduPilot directly from VSCode. All I have to do is make a custom board definition (hwdef.dat) for my specific hardware detailing what components I have and how they are connected, then I can use that board definition in the ArduPilot configurator to flash it. Conveniently, the extension has a built-in tool to make sure that your machine's ArduPilot environment has all of the necessary tools to build and flash the software. I had to install a lot of stuff, such as: Python MAVLink ( pip install pymavlink ) MAV Proxy ( pip install mavproxy ) J-Link ( through SEGGER application ) In addition, I had to create symlinks between ccache and g++, gcc, arm-none-eabi-gcc, and arm-none-eabi-g++. I did so by adding this line to my ZSH profile (~/.zshrc: export PATH=\"/opt/homebrew/opt/ccache/libexec:$PATH\" , then verifying that the installations of ccache, gcc, g++, arm-none-eabi-gcc, and arm-none-eabi-g++ were correct by typing which + the name of the toolchain. I made sure that they were all installed, but I was unclear as to what exactly their purpose was. I did some digging and these were the results I found: GCC: GNU Compiler Collection's C compiler G++: GNU Compiler Collection's C++ compiler arm-none-eabi-gcc: Compiles .c code into machine code for the ARM Cortex-M family of CPUs arm-none-eabi-gcc: Compiles .cpp code into machine code for the ARM Cortex-M family of CPUs Together, these toolchains work together to compile the .c and .cpp files that make up the ArduPilot source code in order to create machine code for the ARM Cortex-M CPU that powers my flight controller (STM32F767ZIT6). { width=400 } 09.09.2025 Today, I did some more research on how to set up the software. I read the ArduPilot documentation, STMicroelectronics documentation on their various apps such as STM32CubeMX, STM32CubeIDE, etc. They have many apps, so it was confusing trying to figure out exactly what purpose each app had and whether or not I needed them. The only STMicroelectronics app that I will need is the STM32CubeProgrammer which will allow me to flash the ArduPilot software to the STM32 with an ST-Link via Serial Wire Debug. 09.15.2025 I dedicated today to working on my GitHub documentation. Mr. Dubick taught the class on how to use GitHub, and I worked on refining format and writing out some pages on Github. 09.16.2025 Today, I printed out the chassis for my drone. Although I intend to make my final parts out of either PETG or ABS with 50-80% infill, I printed this part out of PLA since all of the printers in the lab are loaded with PLA, and since it is easier to work with. To save time, I used 15% infill, and to support overhangs, I used tree supports. After printing the parts out, I confirmed that my battery would fit in the space. The battery was a perfect fit for the space, although I was a little worried about not having enough clearance for screw heads. Although there is space in the CAD mockup, I may inset the screw heads to allow for more room. The main issues with the parts had to do with durability. The parts have long cylinders for screws to slot into and clamp down on the chassis. Although the screws will add a lot of support, the cylinders are brittle and break easily. To fix this issue, I will add fillets to the base of the cylinders. Also, the plates are pretty thin, so I will have to thicken them by 1-2 in order to reduce flexing. 09.17 - 09.24.2025 In this period of time, I continued work on the 3D CAD design of the drone chassis. I made many small changes in order to increase interior volume, reduce weight, increase strength, and cut down on parts. However, I never printed it out since I was not happy with the final result (and eventually I made a new design from the ground up, more on this later). 09.25 - 09.29.2025 I worked on a mini project to practice soldering. The project is an owl with LEDs which activate by touching a capacitive sensor on the front of the board. While the through hole components were very easy to solder, the 2 ICs on the board with small pin pitches were relatively difficult to solder. 09.30.2025 Today, I finished soldering all of the LEDs, then tested the board. Unfortunately, only the outside ring of lights turned on and the \"eyes\" did not work. This is due to an issue with an IC. I'm not sure exactly how I will fix it, but I will likely have to de-solder the chip, clean the IC, clean the pads with a solder wick and flux, then re-solder it. October 10.01.2025 Today, I started setting up my Raspberry Pi 5 with the AI Hat+. I installed the latest release of Pi OS Bookworm onto a microSD card, then plugged the Pi into a monitor to configure it. I then followed this guide to set up the Pi. I started off by setting up PCIe Gen 3.0 by typing sudo raspi-config to bring up the Raspi-Config CLI tool, then enabling PCIe Gen 3.0 speeds under Advanced Options. After that, I ran sudo apt install hailo-all in order to install the following: Hailo kernel device driver and firmware (allows Pi OS to communicate directly with the Hailo-8 NPU) HailoRT middleware software (runtime that handles tasks such as loading the AI model onto the chip and managing inference execution) Hailo Tappas core post-processing libraries (computer vision libraries that handle post-processing tasks such as decoding bounding boxes, converting raw data into masks, and mapping points onto human body parts) rpicam-apps Hailo post-processing software demo stages (Pi OS's camera stack allowing for video recording, image capturing, live feeds, etc.) 10.07.2025 Today, I printed out the bottom plate for my drone, which is where most of the electronics are mounted. printed base plate v1 and front top plate, installed raspberry pi: - holes too big for camera not gripping screws - stands too weak to support camera properly - npu chip slightly pressing on camera --> heating up connector as well as forcing the plate to bend very slightly - redesigned in cad to strengthen camera plate and recess pi mounts by 0.25 mm to get rid of flexing issue 10.08.2025 Today, I focused on getting the AI working on the Raspberry Pi. Up to this point, I was using the pre-existing hailo_inf_fl.json file in Raspberry Pi OS that uses 3 models: yolov8 (object detection/classification), yolov8 pose (pose detection), and scrfd (facial tracking). While the yolov8 models were correctly compiled for the Hailo 8 (the NPU I am using), the scrfd model was compiled for the Hailo 8L NPU, the lower performance version of the Hailo 8. This returned a warning message that I will likely experience lower performance than expected, since the model was compiled for the incorrect architecture. I wanted to get rid of this error, so I looked at the Hailo Model Zoo Github and looked through the models until I found the link for scrfd compiled for the Hailo 8 NPU. Once I found the correct .hef file, I looked at the hailo_inf_fl.json file to see where the current scrfd file is located. It was located at /usr/bin/rpi-camera-assets/scrfd_2.5g.hef, so I deleted it and copied the new scrfd_2.5g.hef file to the same location to ensure that the json file would work as expected and know where to locate the model. When I re-ran rpicam-hello -t 0 --rotation 180 --post-process-file /usr/share/rpi-camera-assets/hailo_inf_fl.json , I no longer got the warning that the model is compiled for the wrong NPU. Although it would have previously worked fine, I wanted to ensure that everything was as optimized as possible to ensure maximum performance and the lowest power consumption possible. printed new base plate, camera is more secure and no longer any flexing issues may add ribs to reduce overall flexing/lack of structural rigidity, but will wait to use petg since it will flex less in petg w/ 67% gyroid infill 10.09.2025 did some refining in Onshape to finish up the back top part (added standoffs to sit flush with base plate) as well as searched for models to use. also fixed owl project by taking a fine tip solder and melting the solder of the ics and melting the excess solder paste that was likely bridging some pads on the small ic. doing this made the owl work perfectly 10.10.2025 printed back top part stress tested new models to test overheating/throttling/melting the chassis (it got hot, but not hot enough to cause damage) by running model the whole class (45 minutes) and periodically checking to see if it was still at 30fps or if it was dropping frames. it didn't drop frames and was able to run continuously mostly thanks to the active cooler turning on its fan and blowing out the hot air. And, when the drone is flying, the pi is at the very front and will get a lot of cool fresh air to cool it down, so even in the worst case scenario, it doesn't throttle. insert video here 10.13.2025 Today, I started off with refining my original chassis design even more. However, I was not very happy with the level of complexity of the parts They were too weak, complicated, and I decided to start fresh by designing a brand new chassis from the ground up. While the original chassis was a heavily modified version of the Source One open-source drone chassis, the new design was my own from the start and was designed around my specific hardware. My overall goals for the new chassis were to increase structural rigidity, reduce the amount of parts, increase 10.16.2025 I dedicated today to working on my portfolio and catching up on my daily log. I also created pages for the smaller projects such as the pen and owl. 10.17.2025 Today, Mr. Dubick taught us how to use Jekyll and GitHub pages. Although I currently use MKDocs for my portfolio, it's useful to know how to use Jekyll in case I want to November December January February March April May June","title":"Daily Log"},{"location":"courses/senior_engineering/daily_log/#honors-advanced-topics-in-engineering-daily-log","text":"Welcome to my daily log for engineering! Here, I will outline what I do every day in class.","title":"Honors Advanced Topics in Engineering Daily Log"},{"location":"courses/senior_engineering/daily_log/#navigation","text":"September October November December January February March April May June","title":"Navigation"},{"location":"courses/senior_engineering/daily_log/#september","text":"","title":"September"},{"location":"courses/senior_engineering/daily_log/#09032025","text":"Today, I continued work on my wooden pen. I took my two blocks of wood and turned them on a lathe. I took a chisel and removed material until the blocks were cylindrical, and when they got to the desired thickness, I used fine grit sandpaper to smooth the two blocks. Now, I have the two wooden components for my pen ready, and now, I can assemble the pen and do all of the finishing touches next class.","title":"09.03.2025"},{"location":"courses/senior_engineering/daily_log/#09042025","text":"Today, I finished my pen. I started off by using the pen press to: Press the pen tip into the bottom end of the lower barrel Press the ink chamber into the top end of the lower barrel Press the clip assembly into the top end of the upper barrel Once I pressed these components, I could assemble the main sections together. I screwed the ink refill into the ink chamber, slid the ring onto the chamber above the lower barrel, and slid the upper barrel above the ring. Once I did that, my pen was done, and it wrote super well, along with looking very cool.","title":"09.04.2025"},{"location":"courses/senior_engineering/daily_log/#09052025","text":"Today, I did some research and work on my capstone project. My goal is to assemble the board as soon as possible, so today, I practiced soldering random components to practice boards to prepare for soldering intricate components on the board.","title":"09.05.2025"},{"location":"courses/senior_engineering/daily_log/#09082025","text":"Today, I researched more about how to configure ArduPilot for a custom board. I decided that I would have to compile ArduPilot from the source code with a custom hwdef.dat file for my specific hardware configuration. From the start, I knew that I wanted to do as much as possible in VSCode, as I am very familiar with it. After doing some researching, I discovered that ArduPilot provides a VSCode integration which allows you to configure and flash ArduPilot directly from VSCode. All I have to do is make a custom board definition (hwdef.dat) for my specific hardware detailing what components I have and how they are connected, then I can use that board definition in the ArduPilot configurator to flash it. Conveniently, the extension has a built-in tool to make sure that your machine's ArduPilot environment has all of the necessary tools to build and flash the software. I had to install a lot of stuff, such as: Python MAVLink ( pip install pymavlink ) MAV Proxy ( pip install mavproxy ) J-Link ( through SEGGER application ) In addition, I had to create symlinks between ccache and g++, gcc, arm-none-eabi-gcc, and arm-none-eabi-g++. I did so by adding this line to my ZSH profile (~/.zshrc: export PATH=\"/opt/homebrew/opt/ccache/libexec:$PATH\" , then verifying that the installations of ccache, gcc, g++, arm-none-eabi-gcc, and arm-none-eabi-g++ were correct by typing which + the name of the toolchain. I made sure that they were all installed, but I was unclear as to what exactly their purpose was. I did some digging and these were the results I found: GCC: GNU Compiler Collection's C compiler G++: GNU Compiler Collection's C++ compiler arm-none-eabi-gcc: Compiles .c code into machine code for the ARM Cortex-M family of CPUs arm-none-eabi-gcc: Compiles .cpp code into machine code for the ARM Cortex-M family of CPUs Together, these toolchains work together to compile the .c and .cpp files that make up the ArduPilot source code in order to create machine code for the ARM Cortex-M CPU that powers my flight controller (STM32F767ZIT6). { width=400 }","title":"09.08.2025"},{"location":"courses/senior_engineering/daily_log/#09092025","text":"Today, I did some more research on how to set up the software. I read the ArduPilot documentation, STMicroelectronics documentation on their various apps such as STM32CubeMX, STM32CubeIDE, etc. They have many apps, so it was confusing trying to figure out exactly what purpose each app had and whether or not I needed them. The only STMicroelectronics app that I will need is the STM32CubeProgrammer which will allow me to flash the ArduPilot software to the STM32 with an ST-Link via Serial Wire Debug.","title":"09.09.2025"},{"location":"courses/senior_engineering/daily_log/#09152025","text":"I dedicated today to working on my GitHub documentation. Mr. Dubick taught the class on how to use GitHub, and I worked on refining format and writing out some pages on Github.","title":"09.15.2025"},{"location":"courses/senior_engineering/daily_log/#09162025","text":"Today, I printed out the chassis for my drone. Although I intend to make my final parts out of either PETG or ABS with 50-80% infill, I printed this part out of PLA since all of the printers in the lab are loaded with PLA, and since it is easier to work with. To save time, I used 15% infill, and to support overhangs, I used tree supports. After printing the parts out, I confirmed that my battery would fit in the space. The battery was a perfect fit for the space, although I was a little worried about not having enough clearance for screw heads. Although there is space in the CAD mockup, I may inset the screw heads to allow for more room. The main issues with the parts had to do with durability. The parts have long cylinders for screws to slot into and clamp down on the chassis. Although the screws will add a lot of support, the cylinders are brittle and break easily. To fix this issue, I will add fillets to the base of the cylinders. Also, the plates are pretty thin, so I will have to thicken them by 1-2 in order to reduce flexing.","title":"09.16.2025"},{"location":"courses/senior_engineering/daily_log/#0917-09242025","text":"In this period of time, I continued work on the 3D CAD design of the drone chassis. I made many small changes in order to increase interior volume, reduce weight, increase strength, and cut down on parts. However, I never printed it out since I was not happy with the final result (and eventually I made a new design from the ground up, more on this later).","title":"09.17 - 09.24.2025"},{"location":"courses/senior_engineering/daily_log/#0925-09292025","text":"I worked on a mini project to practice soldering. The project is an owl with LEDs which activate by touching a capacitive sensor on the front of the board. While the through hole components were very easy to solder, the 2 ICs on the board with small pin pitches were relatively difficult to solder.","title":"09.25 - 09.29.2025"},{"location":"courses/senior_engineering/daily_log/#09302025","text":"Today, I finished soldering all of the LEDs, then tested the board. Unfortunately, only the outside ring of lights turned on and the \"eyes\" did not work. This is due to an issue with an IC. I'm not sure exactly how I will fix it, but I will likely have to de-solder the chip, clean the IC, clean the pads with a solder wick and flux, then re-solder it.","title":"09.30.2025"},{"location":"courses/senior_engineering/daily_log/#october","text":"","title":"October"},{"location":"courses/senior_engineering/daily_log/#10012025","text":"Today, I started setting up my Raspberry Pi 5 with the AI Hat+. I installed the latest release of Pi OS Bookworm onto a microSD card, then plugged the Pi into a monitor to configure it. I then followed this guide to set up the Pi. I started off by setting up PCIe Gen 3.0 by typing sudo raspi-config to bring up the Raspi-Config CLI tool, then enabling PCIe Gen 3.0 speeds under Advanced Options. After that, I ran sudo apt install hailo-all in order to install the following: Hailo kernel device driver and firmware (allows Pi OS to communicate directly with the Hailo-8 NPU) HailoRT middleware software (runtime that handles tasks such as loading the AI model onto the chip and managing inference execution) Hailo Tappas core post-processing libraries (computer vision libraries that handle post-processing tasks such as decoding bounding boxes, converting raw data into masks, and mapping points onto human body parts) rpicam-apps Hailo post-processing software demo stages (Pi OS's camera stack allowing for video recording, image capturing, live feeds, etc.)","title":"10.01.2025"},{"location":"courses/senior_engineering/daily_log/#10072025","text":"Today, I printed out the bottom plate for my drone, which is where most of the electronics are mounted. printed base plate v1 and front top plate, installed raspberry pi: - holes too big for camera not gripping screws - stands too weak to support camera properly - npu chip slightly pressing on camera --> heating up connector as well as forcing the plate to bend very slightly - redesigned in cad to strengthen camera plate and recess pi mounts by 0.25 mm to get rid of flexing issue","title":"10.07.2025"},{"location":"courses/senior_engineering/daily_log/#10082025","text":"Today, I focused on getting the AI working on the Raspberry Pi. Up to this point, I was using the pre-existing hailo_inf_fl.json file in Raspberry Pi OS that uses 3 models: yolov8 (object detection/classification), yolov8 pose (pose detection), and scrfd (facial tracking). While the yolov8 models were correctly compiled for the Hailo 8 (the NPU I am using), the scrfd model was compiled for the Hailo 8L NPU, the lower performance version of the Hailo 8. This returned a warning message that I will likely experience lower performance than expected, since the model was compiled for the incorrect architecture. I wanted to get rid of this error, so I looked at the Hailo Model Zoo Github and looked through the models until I found the link for scrfd compiled for the Hailo 8 NPU. Once I found the correct .hef file, I looked at the hailo_inf_fl.json file to see where the current scrfd file is located. It was located at /usr/bin/rpi-camera-assets/scrfd_2.5g.hef, so I deleted it and copied the new scrfd_2.5g.hef file to the same location to ensure that the json file would work as expected and know where to locate the model. When I re-ran rpicam-hello -t 0 --rotation 180 --post-process-file /usr/share/rpi-camera-assets/hailo_inf_fl.json , I no longer got the warning that the model is compiled for the wrong NPU. Although it would have previously worked fine, I wanted to ensure that everything was as optimized as possible to ensure maximum performance and the lowest power consumption possible. printed new base plate, camera is more secure and no longer any flexing issues may add ribs to reduce overall flexing/lack of structural rigidity, but will wait to use petg since it will flex less in petg w/ 67% gyroid infill","title":"10.08.2025"},{"location":"courses/senior_engineering/daily_log/#10092025","text":"did some refining in Onshape to finish up the back top part (added standoffs to sit flush with base plate) as well as searched for models to use. also fixed owl project by taking a fine tip solder and melting the solder of the ics and melting the excess solder paste that was likely bridging some pads on the small ic. doing this made the owl work perfectly","title":"10.09.2025"},{"location":"courses/senior_engineering/daily_log/#10102025","text":"printed back top part stress tested new models to test overheating/throttling/melting the chassis (it got hot, but not hot enough to cause damage) by running model the whole class (45 minutes) and periodically checking to see if it was still at 30fps or if it was dropping frames. it didn't drop frames and was able to run continuously mostly thanks to the active cooler turning on its fan and blowing out the hot air. And, when the drone is flying, the pi is at the very front and will get a lot of cool fresh air to cool it down, so even in the worst case scenario, it doesn't throttle. insert video here","title":"10.10.2025"},{"location":"courses/senior_engineering/daily_log/#10132025","text":"Today, I started off with refining my original chassis design even more. However, I was not very happy with the level of complexity of the parts They were too weak, complicated, and I decided to start fresh by designing a brand new chassis from the ground up. While the original chassis was a heavily modified version of the Source One open-source drone chassis, the new design was my own from the start and was designed around my specific hardware. My overall goals for the new chassis were to increase structural rigidity, reduce the amount of parts, increase","title":"10.13.2025"},{"location":"courses/senior_engineering/daily_log/#10162025","text":"I dedicated today to working on my portfolio and catching up on my daily log. I also created pages for the smaller projects such as the pen and owl.","title":"10.16.2025"},{"location":"courses/senior_engineering/daily_log/#10172025","text":"Today, Mr. Dubick taught us how to use Jekyll and GitHub pages. Although I currently use MKDocs for my portfolio, it's useful to know how to use Jekyll in case I want to","title":"10.17.2025"},{"location":"courses/senior_engineering/daily_log/#november","text":"","title":"November"},{"location":"courses/senior_engineering/daily_log/#december","text":"","title":"December"},{"location":"courses/senior_engineering/daily_log/#january","text":"","title":"January"},{"location":"courses/senior_engineering/daily_log/#february","text":"","title":"February"},{"location":"courses/senior_engineering/daily_log/#march","text":"","title":"March"},{"location":"courses/senior_engineering/daily_log/#april","text":"","title":"April"},{"location":"courses/senior_engineering/daily_log/#may","text":"","title":"May"},{"location":"courses/senior_engineering/daily_log/#june","text":"","title":"June"},{"location":"courses/senior_engineering/owl/","text":"Owl Project In order to practice soldering, I completed a mini-project where I soldered LEDs and other components to a board in the shape of an owl. This project featured both through-hole and surface-mount soldering, which was useful for refreshing my soldering skills. Manufacturing Since I am more experienced with through hole soldering and find it easier, I started the project off with soldering all of the through hole components, such as resistors, transistors, capacitors, LEDs, and the USB-C port. After I successfully soldered all of the through hole components, I had to solder the 2 surface mount components. It was quite challenging to do so, and I used solder paste and a fine tip soldering iron to solder the components. Unfortunately, after soldering the ICs on, only the outer ring of LEDs lit up; the inner LEDs did not work. I suspected that there was a bridge between two pads of the IC due to unmelted solder paste, so I took a fine tip soldering iron, ran it between all of the legs of the ICs, and melted all excess solder paste. After doing so, all of the LEDs lit up and the board functioned perfectly. What I Learned From doing this project, I learned a lot about surface mount soldering. I learned use solder paste to solder SMD components, and I learned how to troubleshoot surface mount components that aren't working as expected. Practicing will help me eventually surface the intricate SMD components to the flight controller board of my drone.","title":"Owl"},{"location":"courses/senior_engineering/owl/#owl-project","text":"In order to practice soldering, I completed a mini-project where I soldered LEDs and other components to a board in the shape of an owl. This project featured both through-hole and surface-mount soldering, which was useful for refreshing my soldering skills.","title":"Owl Project"},{"location":"courses/senior_engineering/owl/#manufacturing","text":"Since I am more experienced with through hole soldering and find it easier, I started the project off with soldering all of the through hole components, such as resistors, transistors, capacitors, LEDs, and the USB-C port. After I successfully soldered all of the through hole components, I had to solder the 2 surface mount components. It was quite challenging to do so, and I used solder paste and a fine tip soldering iron to solder the components. Unfortunately, after soldering the ICs on, only the outer ring of LEDs lit up; the inner LEDs did not work. I suspected that there was a bridge between two pads of the IC due to unmelted solder paste, so I took a fine tip soldering iron, ran it between all of the legs of the ICs, and melted all excess solder paste. After doing so, all of the LEDs lit up and the board functioned perfectly.","title":"Manufacturing"},{"location":"courses/senior_engineering/owl/#what-i-learned","text":"From doing this project, I learned a lot about surface mount soldering. I learned use solder paste to solder SMD components, and I learned how to troubleshoot surface mount components that aren't working as expected. Practicing will help me eventually surface the intricate SMD components to the flight controller board of my drone.","title":"What I Learned"},{"location":"courses/senior_engineering/pcb_milling/","text":"PCB Milling In this project, I used MakerCAM and the CNC machines in the Fab Lab in order to create GCode for a board and manufacture it when given gerber files. Software and Hardware Used: Carvera Desktop CNC Machine : Machine that milled out the board Makera CAM : Software to generate GCode from gerber and drill files Carvera Controller : Software to control the CNC Machine Workflow for Milling a Board with the Carvera Desktop CNC Machine Open Makera CAM and open a 3-Axis project Edit the material settings to be a 127mm x 101mm x 1.7mm PCB Import the files with File \u21d2 Import PCB Select all of the imported vectors and click the letter M to move them. Set the origin to the bottom left corner and type in the coordinates (6,6) to move the bottom left corner of the vectors to (6,6) in the workspace. Create a 2D Pocket cut toolpath by selecting only the edge.cuts and f.cu vectors, then clicking 2D Path \u21d2 2D Pocket. Edit the 2D Pocket settings with the following settings: End depth: 0.05mm Tools: 0.8mm Corn and 0.2mm*30\u00b0 Engraving (metal) Ensure that for these tools, the material selected is \"PCB\" Once these settings are applied, select \"calculate,\" which should make a toolpath appear on the screen. If it looks right, then hide it. If not, re-do the process. Hide everything except for the .drl files. Then, select all of the holes and click 2D Path \u21d2 2D Drilling. Edit the 2D Drilling settings with the following settings: End depth: 1.70mm Tools: 0.8mm Corn (ensure material is set to \"PCB\") Once these settings are applied, select \"calculate,\" which should make a toolpath appear on the screen. If it looks right, then hide it. If not, re-do the process. Deselect everything, and hide all vectors except for the edge.cuts layer. Select only the inner line, then click 2D Path \u21d2 2D Contour. Edit the 2D Contour settings with the following settings: End depth: 1.70mm Tools: 0.8mm Corn (ensure material is set to \"PCB\") Once these settings are applied, select \"calculate,\" which should make a toolpath appear on the screen. If it looks right, then hide it. If not, re-do the process. Hide everything except for the 3 toolpaths. If everything looks correct, export them by clicking Export Toolpaths in the top right of the screen and selecting the 3 toolpaths. It should save a .nc file. Creating GCode in Makera CAM At the start, Mr. Dubick provided the class with gerber files to create the board from. Once I downloaded these files, I imported them into Makera CAM with File \u21d2 Import PCB. Before doing anything else, I changed the material settings to 127mm x 101mm x 1.7mm (L x W x H) since the blank PCB that I milled was that size. After setting the workspace up, I used the Translate tool to move the board to the coordinates (6,6). Moving the board here allows for the board to be milled with very little wasted space while still allowing ample room for securing the board to the CNC machine. Next, I hid the .drl and f.cu_pad files, leaving only the edge.cuts and f.cu files visible. I selected them and selected 2D Path \u21d2 2D Pocket, which brought up many options. I made sure to change the end depth to 0.05mm and to change the tools to 0.8mm Corn and 0.2mm*30\u00b0 Engraving (Metal) for the 2D Pocket cut. The purpose of the 2D Pocket is to take off the very top layer of copper on the PCB board, leaving behind only the desired traces. Once I had all of my desired settings, I pressed \"calculate\", and it displayed the toolpath for the 2D Pocket cut. Once I created the toolpath for the 2D Pocket cut, the next step was to create a toolpath for drilling the holes in the board. To do so, I hid the edge.cuts, f.cu, and 2D Pocket and showed only the 2 drill files. I selected them, then selected 2D Path \u21d2 2D Drilling in order to drill holes in the board. I set the tool to 0.8mm Corn and end depth to 1.7mm to ensure that the holes are drilled completely though the board. Lastly, I needed to cut out the board. To do so, I hid everything except the edge.cuts vector, then selected 2D Path \u21d2 2D Contour. Again, I chose 0.8mm Corn and set the end depth to 1.7mm so the board gets cut out completely. I also added 3 tabs to make sure that the board would stay in place when it gets cut. Once I created the 3 different toolpaths, I exported them to a .nc (GCode) file so I could import it into the Carvera Controller application. Milling the Board with the CNC Machine using Carvera Controller (Workflow) After I successfully created a GCode file for the CNC machine, I had to mill the board out. To do so, I obtained a blank PCB that matched the dimensions I specified in Makera CAM (127mm x 101mm x 1.7mm), then I put it in the machine and clamped it down. After doing so, I used the Carvera Controller Software to load my GCode and start the job. To do so, I followed this workflow: Open Carvera Controller and connect to the CNC via USB Before doing anything, ensure that the probe is charged to at least 3.6V under \"Tool Status and Control\" In the top right corner, click \"Switch to Display Manual Control Interface,\" then click the \"Home\" button In the bottom left corner, open the GCode file from the computer. To check that everything is correct, click \"Switch to Display File Preview Interface\" in order to preview the toolpath If everything looks as expected, click \"Config and Run\" and ensure that the options for \"auto vacuum\" and \"auto leveling\" are enabled. Once everything looks good, click \"run.\" After following these steps, the machine took ~30 minutes to mill out my board. After it was done, all I had to do was break the 3 tabs that I set, and I was done!","title":"PCB Milling"},{"location":"courses/senior_engineering/pcb_milling/#pcb-milling","text":"In this project, I used MakerCAM and the CNC machines in the Fab Lab in order to create GCode for a board and manufacture it when given gerber files.","title":"PCB Milling"},{"location":"courses/senior_engineering/pcb_milling/#software-and-hardware-used","text":"Carvera Desktop CNC Machine : Machine that milled out the board Makera CAM : Software to generate GCode from gerber and drill files Carvera Controller : Software to control the CNC Machine","title":"Software and Hardware Used:"},{"location":"courses/senior_engineering/pcb_milling/#workflow-for-milling-a-board-with-the-carvera-desktop-cnc-machine","text":"Open Makera CAM and open a 3-Axis project Edit the material settings to be a 127mm x 101mm x 1.7mm PCB Import the files with File \u21d2 Import PCB Select all of the imported vectors and click the letter M to move them. Set the origin to the bottom left corner and type in the coordinates (6,6) to move the bottom left corner of the vectors to (6,6) in the workspace. Create a 2D Pocket cut toolpath by selecting only the edge.cuts and f.cu vectors, then clicking 2D Path \u21d2 2D Pocket. Edit the 2D Pocket settings with the following settings: End depth: 0.05mm Tools: 0.8mm Corn and 0.2mm*30\u00b0 Engraving (metal) Ensure that for these tools, the material selected is \"PCB\" Once these settings are applied, select \"calculate,\" which should make a toolpath appear on the screen. If it looks right, then hide it. If not, re-do the process. Hide everything except for the .drl files. Then, select all of the holes and click 2D Path \u21d2 2D Drilling. Edit the 2D Drilling settings with the following settings: End depth: 1.70mm Tools: 0.8mm Corn (ensure material is set to \"PCB\") Once these settings are applied, select \"calculate,\" which should make a toolpath appear on the screen. If it looks right, then hide it. If not, re-do the process. Deselect everything, and hide all vectors except for the edge.cuts layer. Select only the inner line, then click 2D Path \u21d2 2D Contour. Edit the 2D Contour settings with the following settings: End depth: 1.70mm Tools: 0.8mm Corn (ensure material is set to \"PCB\") Once these settings are applied, select \"calculate,\" which should make a toolpath appear on the screen. If it looks right, then hide it. If not, re-do the process. Hide everything except for the 3 toolpaths. If everything looks correct, export them by clicking Export Toolpaths in the top right of the screen and selecting the 3 toolpaths. It should save a .nc file.","title":"Workflow for Milling a Board with the Carvera Desktop CNC Machine"},{"location":"courses/senior_engineering/pcb_milling/#creating-gcode-in-makera-cam","text":"At the start, Mr. Dubick provided the class with gerber files to create the board from. Once I downloaded these files, I imported them into Makera CAM with File \u21d2 Import PCB. Before doing anything else, I changed the material settings to 127mm x 101mm x 1.7mm (L x W x H) since the blank PCB that I milled was that size. After setting the workspace up, I used the Translate tool to move the board to the coordinates (6,6). Moving the board here allows for the board to be milled with very little wasted space while still allowing ample room for securing the board to the CNC machine. Next, I hid the .drl and f.cu_pad files, leaving only the edge.cuts and f.cu files visible. I selected them and selected 2D Path \u21d2 2D Pocket, which brought up many options. I made sure to change the end depth to 0.05mm and to change the tools to 0.8mm Corn and 0.2mm*30\u00b0 Engraving (Metal) for the 2D Pocket cut. The purpose of the 2D Pocket is to take off the very top layer of copper on the PCB board, leaving behind only the desired traces. Once I had all of my desired settings, I pressed \"calculate\", and it displayed the toolpath for the 2D Pocket cut. Once I created the toolpath for the 2D Pocket cut, the next step was to create a toolpath for drilling the holes in the board. To do so, I hid the edge.cuts, f.cu, and 2D Pocket and showed only the 2 drill files. I selected them, then selected 2D Path \u21d2 2D Drilling in order to drill holes in the board. I set the tool to 0.8mm Corn and end depth to 1.7mm to ensure that the holes are drilled completely though the board. Lastly, I needed to cut out the board. To do so, I hid everything except the edge.cuts vector, then selected 2D Path \u21d2 2D Contour. Again, I chose 0.8mm Corn and set the end depth to 1.7mm so the board gets cut out completely. I also added 3 tabs to make sure that the board would stay in place when it gets cut. Once I created the 3 different toolpaths, I exported them to a .nc (GCode) file so I could import it into the Carvera Controller application.","title":"Creating GCode in Makera CAM"},{"location":"courses/senior_engineering/pcb_milling/#milling-the-board-with-the-cnc-machine-using-carvera-controller-workflow","text":"After I successfully created a GCode file for the CNC machine, I had to mill the board out. To do so, I obtained a blank PCB that matched the dimensions I specified in Makera CAM (127mm x 101mm x 1.7mm), then I put it in the machine and clamped it down. After doing so, I used the Carvera Controller Software to load my GCode and start the job. To do so, I followed this workflow: Open Carvera Controller and connect to the CNC via USB Before doing anything, ensure that the probe is charged to at least 3.6V under \"Tool Status and Control\" In the top right corner, click \"Switch to Display Manual Control Interface,\" then click the \"Home\" button In the bottom left corner, open the GCode file from the computer. To check that everything is correct, click \"Switch to Display File Preview Interface\" in order to preview the toolpath If everything looks as expected, click \"Config and Run\" and ensure that the options for \"auto vacuum\" and \"auto leveling\" are enabled. Once everything looks good, click \"run.\" After following these steps, the machine took ~30 minutes to mill out my board. After it was done, all I had to do was break the 3 tabs that I set, and I was done!","title":"Milling the Board with the CNC Machine using Carvera Controller (Workflow)"},{"location":"courses/senior_engineering/pen/","text":"Custom Wooden Pen In this project, I created a custom pen with a pen kit and wood. I used tools such as a drill, lathe, and band saw to custom make the wood accents on the pen. Making the Wooden Barrels I started the process by assembling the two pieces of wood that go around the barrels. I decided to make the pen out of purpleheart and birch, since I really liked the look of the dark purple and the light wood contrasting each other. The first step was to cut two pieces of 1\" long purpleheart wood on the band saw, then cutting those in half to form 4 pieces of 0.5\" thick wood. Then, I cut 2 thin pieces of birch to put in between the purpleheart pieces. Once I had all the pieces, I clamped and glued together the wood to form two blocks of wood that was mostly purpleheart with a thin piece of birch in the middle. I let the glue set overnight. While the glue was drying, I took the 2 brass barrels from the pen kit and made them rough by sanding them. This allows for the barrel to bond better with the superglue when they get glued inside the wood. After the glue dried, I drilled a hole down the middle. Then, I lined the hole in each wood block with superglue, then inserted a sanded barrel into each block. I let it dry overnight. After the barrel fully dried, I sanded the corners in order to make turning it on the lathe easier. After doing so, I took my pieces of wood and put them on the lathe. I then used various chisels to trim off most of the material to make the wood blocks round and easy to grip. Assembling the Pen Now that I had the two wooden barrels, I could assemble the pen. I used the pen press to do the following: Press the pen tip into the bottom end of the lower barrel Press the ink chamber into the top end of the lower barrel Press the clip assembly into the top end of the upper barrel Once I pressed these components, I could assemble the main sections together. I screwed the ink refill into the ink chamber, slid the ring onto the chamber above the lower barrel, and slid the upper barrel above the ring. Once I did that, my pen was done, and it wrote super well, along with looking very cool.","title":"Pen"},{"location":"courses/senior_engineering/pen/#custom-wooden-pen","text":"In this project, I created a custom pen with a pen kit and wood. I used tools such as a drill, lathe, and band saw to custom make the wood accents on the pen.","title":"Custom Wooden Pen"},{"location":"courses/senior_engineering/pen/#making-the-wooden-barrels","text":"I started the process by assembling the two pieces of wood that go around the barrels. I decided to make the pen out of purpleheart and birch, since I really liked the look of the dark purple and the light wood contrasting each other. The first step was to cut two pieces of 1\" long purpleheart wood on the band saw, then cutting those in half to form 4 pieces of 0.5\" thick wood. Then, I cut 2 thin pieces of birch to put in between the purpleheart pieces. Once I had all the pieces, I clamped and glued together the wood to form two blocks of wood that was mostly purpleheart with a thin piece of birch in the middle. I let the glue set overnight. While the glue was drying, I took the 2 brass barrels from the pen kit and made them rough by sanding them. This allows for the barrel to bond better with the superglue when they get glued inside the wood. After the glue dried, I drilled a hole down the middle. Then, I lined the hole in each wood block with superglue, then inserted a sanded barrel into each block. I let it dry overnight. After the barrel fully dried, I sanded the corners in order to make turning it on the lathe easier. After doing so, I took my pieces of wood and put them on the lathe. I then used various chisels to trim off most of the material to make the wood blocks round and easy to grip.","title":"Making the Wooden Barrels"},{"location":"courses/senior_engineering/pen/#assembling-the-pen","text":"Now that I had the two wooden barrels, I could assemble the pen. I used the pen press to do the following: Press the pen tip into the bottom end of the lower barrel Press the ink chamber into the top end of the lower barrel Press the clip assembly into the top end of the upper barrel Once I pressed these components, I could assemble the main sections together. I screwed the ink refill into the ink chamber, slid the ring onto the chamber above the lower barrel, and slid the upper barrel above the ring. Once I did that, my pen was done, and it wrote super well, along with looking very cool.","title":"Assembling the Pen"}]}